---
title: "Pk Variant Calling Workflow"
author: "Jacob Westaway"
date: "Last updated on `r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    toc_depth: 1
  html_document:
    df_print: paged
    toc: yes
header-includes:
  \usepackage{float}
  \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

# About.
 - This workflow is run both on a remote HPC server and local machine. Chunks with PBS scripts are those run on the remote server. 
 - The server used is Cheetah, Charles Darwin University's high performance computing infrastructure.
 - There are three sets of data used in this workflow:
  - 'Sanger Subset' = 14 samples - an initial subset of samples sequenced by Sanger. **CORRECTION:** Not actually Sanger, but the name has not been changed as this would create too much of a burden.
  - 'Sanger 100' = 14 samples - a subset of 100 samples sequenced by Sanger (full dataset = pk_pipeline/Sanger_100/pk_data/reads/).
  - 'ZB 100' = 14 samples - a subset of 100 samples sequenced by ZB's group in Singapore. (full dataset = pk_pipeline/ZB_100/pk_data/batch*.zip)

# Quality Control

## FastQC

File = 01_QC.pbs 
Version(s) = 0.10.1

[FastQC](https://github.com/s-andrews/FastQC) was run using the shared folder (/usr/local/) on Cheetah.

```{r, eval=F}
#!/bin/bash
#PBS -N fastqc
#PBS -j oe
#PBS -m ae
#PBS -l select=1:ncpus=10:mem=40gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to fastqc"
export PATH=$PATH:/usr/local/FastQC

echo "---------------------------------------"
echo "Change to current working directory"
cd pk_pipeline

echo "---------------------------------------"
echo "Set environment variable"
INPUTDIR="pk_data/fastq"
OUTDIR="outputs/fastqc"
mkdir $OUTDIR

echo "---------------------------------------"
echo "Execute fastqc"
fastqc -t 1 -o $OUTDIR $INPUTDIR/*.fastq.gz

echo "---------------------------------------"
echo "Finsihed!"
```

## MultiQC 

File = 02_MultiQC.pbs
Version(s) = 0.1.9

Due to software limitations on Cheetah, [MultiQC](https://github.com/ewels/MultiQC) was run using a singularity image: `singularity pull library://kgillinder/analysis_pipelines/multiqc:v0.1.9`, that was downloaded into a directory called tools. This will serve as a directory for resources not available on Cheetah.

```{r, eval=F}
#!/bin/bash
#PBS -N multiqc
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=40gb
#PBS -l walltime=04:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to multiqc"
export PATH=$PATH:/usr/local/singularity/latest/bin

echo "---------------------------------------"
echo "Set environment variable"
OUTDIR="pk_pipeline/outputs/fastqc"

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec ~/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

## Trimming 

File = 03_Trim.pbs
Version(s) = 3.1.0 (singularity), 0.6.4 (trim-galore) & 20171222 (parallel)

Next was quality and adaptor trimming, which was executed with [Trim_Galore](https://github.com/FelixKrueger/TrimGalore/blob/master/Docs/Trim_Galore_User_Guide.md), a wrapper around Cutadapt and FastQC written by Felix Krueger. 
Trim_Galore was used in combination with [GNU parallel](https://www.gnu.org/software/parallel/parallel_tutorial.html), which is needed to handle the multiple file inputs.
Both tools are available on Cheetah under (/usr/local/).
Trim_Galore arguments: 
  • Illumina - Illumina specific (Nextera) adaptors
  • Paired - "Using this option lets you discard too short read pairs without disturbing the sequence-by-sequence order of FastQ files which is required by many aligners."
  • FastQC - to get a fastqc output after.
  • All other paramaters were default.
parallel arguments
  • xapply - runs each pair (if not included then Trim_Galore will run every combination).
  • ::: - specifies input files to parallel, and is needed to supply the correct sample pairs to Trim_Galore.
  • j - running n jobs in parallel.

Due to software limitations on Cheetah, Trim Galore was run using a singularity image: `singularity pull library://jemten/mip_containers/trim-galore:0.6.4`.

```{r, eval=F}
#!/bin/bash
#PBS -N trim
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=20
#PBS -l mem=40gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export paths and load modules"
export PATH=$PATH:/usr/local/singularity/latest/bin
export PATH=$PATH:/usr/local/parallel_20171222/bin/

echo "---------------------------------------"
echo 'Change to current working directory' 
cd pk_pipeline

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="outputs/trimmed"
INPUTDIR="pk_data/fastq"

echo "---------------------------------------"
echo 'Make output dirs'
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Exectue trim_galore for quality and adapter trimming'
parallel -j15 --xapply singularity exec ~/pk_pipeline/tools/singularity/trim-galore_0.6.4.sif trim_galore --illumina --paired --fastqc -o $OUTDIR ::: $INPUTDIR/*1.fastq.gz ::: $INPUTDIR/*2.fastq.gz

echo "---------------------------------------"
echo "Finsihed!"
```

## MultiQC on trimmed reads

File = 04_MultiQC_trimmed.pbs
Version(s) = 0.1.9

Due to software limitations on Cheetah, [MultiQC](https://github.com/ewels/MultiQC) was run using a singularity image: `singularity pull library://kgillinder/analysis_pipelines/multiqc:v0.1.9`.

```{R, eval=F}
#!/bin/bash
#PBS -N multiqc
#PBS -j oe
#PBS -m ae
#PBS -l ndoes=1
#PBS -l ncpus=10
#PBS -l mem=40gb
#PBS -l walltime=04:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to multiqc"
export PATH=$PATH:/usr/local/singularity/latest/bin

echo "---------------------------------------"
echo "Set environment variable"
OUTDIR="pk_pipeline/outputs/trimmed"

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec ~/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

# Mapping/Alignment

Using [BWA](http://bio-bwa.sourceforge.net/bwa.shtml), with `bwa index` for indexing and `bwa mem` for alignments.
For `bwa index`, -p represents the prefix of the output database, and -a the algorithm for constructing the index. 

Comparing 2 methods:
	• Alignment with human first (samtools or bmtagger)
		○ Initial Sanger dataset
		○ New Sanger dataset
    ○ ZB dataset
	• Direct alignment to Pk genome without removing human contamination 
		○ Initial Sanger dataset
    ○ New Sanger dataset
    ○ ZB dataset

## Index host genome

File = 05_Index_hg.pbs
Version(s) = 0.7.10

Reference genome was downloaded prior to script submission.

```{R, eval=F}
#!/bin/bash
#PBS -N Index_hg
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to bwa"
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Create and change to working directory' 
cd pk_pipeline/ref_genomes/human

echo "---------------------------------------"
echo 'gunzip fasta file'
tar zvfx GRCh38.tar.gz

echo "---------------------------------------"
echo 'Execute indexing with BWA'
bwa index -p human_index -a bwtsw GRCh38d1_noalt.fa

echo "---------------------------------------"
echo "Finsihed!"
```

## Index Pk reference genome

File = 06_Index_Reference.pbs
Version(s) = 0.7.10

Arguments 
  • a - Algorithm for constructing BWT index. Available options are:
    • is	- Linear-time algorithm for constructing suffix array. It requires 5.37N memory where N is the size of the database. IS is moderately fast, but does not work with database larger than 2GB. IS is the default algorithm due to its simplicity. The current codes for IS algorithm are reimplemented by Yuta Mori.
    • bwtsw	- Algorithm implemented in BWT-SW. This method works with the whole human genome.

```{R, eval=F}
#!/bin/bash
#PBS -N Index_Ref
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=50gb
#PBS -l walltime=6:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to bwa"
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to current working directory' 
cd pk_pipeline/ref_genomes/PKA1H1/fasta

echo "---------------------------------------"
echo 'gunzip fasta file'
gzip -d strain_A1_H.1.Icor.fasta.gz

echo "---------------------------------------"
echo 'Execute indexing with BWA'
bwa index -p PKA1H1_index -a is strain_A1_H.1.Icor.fasta

echo "---------------------------------------"
echo "Finsihed!"
```

### Initial Sanger Subset

### Direct Pk Alignment

File = 07_Alignment_pk_direct.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

BWA was used for the alignment, with the outputs converted into bam format and sorted by [samtools](https://www.htslib.org/).

BWA arguments 
  • M - Mark shorter split hits as secondary (for Picard compatibility).
  • R - Complete read group header line. ’\t’ can be used in STR and will be converted to a TAB in the output SAM/BAM. The read group ID will be attached to every read in the output. An example is ’@RG\tID:foo\tSM:bar’. 

Samtools view arguments
  • u - Output uncompressed BAM. This option saves time spent on compression/decompression and is thus preferred when the output is piped to another samtools command.
  • S - sam file compatibility.

Samtools sort arguments
  • n - Sort by name.
  • o - Write final sorted output to FILE (rather than standard output).

```{R,eval=F}
#!/bin/bash
#PBS -N Align_pk_direct
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/outputs/alignment/direct_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Change to working directory' 
cd pk_pipeline/outputs/trimmed

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS01_124_1_val_1.fq.gz PKAS01_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS01_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS02_124\tPL:ILLUMINA" $INDEXTDIR PKAS02_124_1_val_1.fq.gz PKAS02_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS02_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS04_124\tPL:ILLUMINA" $INDEXTDIR PKAS04_124_1_val_1.fq.gz PKAS04_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS04_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS05_124\tPL:ILLUMINA" $INDEXTDIR PKAS05_124_1_val_1.fq.gz PKAS05_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS05_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS06_124\tPL:ILLUMINA" $INDEXTDIR PKAS06_124_1_val_1.fq.gz PKAS06_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS06_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS07_124\tPL:ILLUMINA" $INDEXTDIR PKAS07_124_1_val_1.fq.gz PKAS07_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS07_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS08_124\tPL:ILLUMINA" $INDEXTDIR PKAS08_124_1_val_1.fq.gz PKAS08_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS08_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS09_124\tPL:ILLUMINA" $INDEXTDIR PKAS09_124_1_val_1.fq.gz PKAS09_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS09_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS10_124\tPL:ILLUMINA" $INDEXTDIR PKAS10_124_1_val_1.fq.gz PKAS10_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS10_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS11_124\tPL:ILLUMINA" $INDEXTDIR PKAS11_124_1_val_1.fq.gz PKAS11_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS11_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS12_124\tPL:ILLUMINA" $INDEXTDIR PKAS12_124_1_val_1.fq.gz PKAS12_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS12_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS13_124\tPL:ILLUMINA" $INDEXTDIR PKAS13_124_1_val_1.fq.gz PKAS13_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS13_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS14_124\tPL:ILLUMINA" $INDEXTDIR PKAS14_124_1_val_1.fq.gz PKAS14_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS14_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS15_124\tPL:ILLUMINA" $INDEXTDIR PKAS15_124_1_val_1.fq.gz PKAS15_124_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS15_124.bam

echo "---------------------------------------"
echo "Finsihed!"
```

### Mapping to host genome first

#### Alignment and sort to BAM 

File = 08_Align_to_hg.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

```{R, eval=F}
#!/bin/bash
#PBS -N Align_Pk_no_host
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=200gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au
echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/outputs/alignment/hg_removed_alignment/hg_rem_fastq/

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/outputs/alignment/hg_removed_alignment/pk_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS01_124_unmapped_R1.fq.gz PKAS01_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS01_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS02_124_unmapped_R1.fq.gz PKAS02_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS02_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS04_124_unmapped_R1.fq.gz PKAS04_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS04_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS05_124_unmapped_R1.fq.gz PKAS05_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS05_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS06_124_unmapped_R1.fq.gz PKAS06_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS06_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS07_124_unmapped_R1.fq.gz PKAS07_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS07_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS08_124_unmapped_R1.fq.gz PKAS08_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS08_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS09_124_unmapped_R1.fq.gz PKAS09_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS09_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS10_124_unmapped_R1.fq.gz PKAS10_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS10_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS11_124_unmapped_R1.fq.gz PKAS11_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS11_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS12_124_unmapped_R1.fq.gz PKAS12_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS12_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS13_124_unmapped_R1.fq.gz PKAS13_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS13_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS14_124_unmapped_R1.fq.gz PKAS14_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS14_124.bam
bwa mem -t 20 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS15_124_unmapped_R1.fq.gz PKAS15_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS15_124.bam

echo "---------------------------------------"
echo "Finsihed!"
```

#### Get unaligned read pairs and fastqs
File = 09_Fastq_from_hg_align.pbs
Version = 0.7.10 (bwa) & 1.12 (samtools)

After aligning samples to the human genome, we get the reads that did not align (-f 12 -F 256) and store them as bam files. 
These bam fies are then converted into fastq files to undergo alignment to the Pk genome.

Samtools view arguments
  • b - Output BAM. 
  • f - Only output alignments with all bits set in INT present in the FLAG field. 
  • F - Do not output alignments with any bits set in INT present in the FLAG field.

Samtools bam2fq arguments
  • N - don't append /1 and /2 to the read name.

```{R,eval=F}
#!/bin/bash
#PBS -N fastq_from_hg_align
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/sortedbam/

echo "---------------------------------------"
echo 'Set environment vars for bam file step'
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/unaligned_pairs/"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Get un-aligned reads (Pk reads)'

samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS01_124_unaligned.bam PKAS01_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS02_124_unaligned.bam PKAS02_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS04_124_unaligned.bam PKAS04_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS05_124_unaligned.bam PKAS05_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS06_124_unaligned.bam PKAS06_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS07_124_unaligned.bam PKAS07_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS08_124_unaligned.bam PKAS08_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS09_124_unaligned.bam PKAS09_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS10_124_unaligned.bam PKAS10_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS11_124_unaligned.bam PKAS11_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS12_124_unaligned.bam PKAS12_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS13_124_unaligned.bam PKAS13_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS14_124_unaligned.bam PKAS14_124.bam
samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PKAS15_124_unaligned.bam PKAS15_124.bam

echo "---------------------------------------"
echo 'Set environment vars for fastq file step'
cd $OUTDIR
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/human/GRCh38d1_noalt.fa"

echo "---------------------------------------"
echo 'Get fastqs from unaligned pk read pairs'
samtools bam2fq -@ 10 -1 PKAS01_124_unmapped_R1.fq.gz -2 PKAS01_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS01_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS02_124_unmapped_R1.fq.gz -2 PKAS02_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS02_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS04_124_unmapped_R1.fq.gz -2 PKAS04_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS04_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS05_124_unmapped_R1.fq.gz -2 PKAS05_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS05_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS06_124_unmapped_R1.fq.gz -2 PKAS06_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS06_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS07_124_unmapped_R1.fq.gz -2 PKAS07_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS07_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS08_124_unmapped_R1.fq.gz -2 PKAS08_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS08_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS09_124_unmapped_R1.fq.gz -2 PKAS09_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS09_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS10_124_unmapped_R1.fq.gz -2 PKAS10_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS10_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS11_124_unmapped_R1.fq.gz -2 PKAS11_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS11_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS12_124_unmapped_R1.fq.gz -2 PKAS12_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS12_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS13_124_unmapped_R1.fq.gz -2 PKAS13_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS13_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS14_124_unmapped_R1.fq.gz -2 PKAS14_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS14_124_unaligned.bam
samtools bam2fq -@ 10 -1 PKAS15_124_unmapped_R1.fq.gz -2 PKAS15_124_unmapped_R2.fq.gz -N --reference $INDEXTDIR  -s /dev/null PKAS15_124_unaligned.bam

echo "---------------------------------------"
echo "Finsihed!"
```

#### Alignment to Pk reference genome

File = 10_Alignment_hg_removed.pbs
Version = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Align_Pk_no_host
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au
echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/unaligned_pairs/

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/pk_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS01_124_unmapped_R1.fq.gz PKAS01_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS01_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS02_124_unmapped_R1.fq.gz PKAS02_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS02_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS04_124_unmapped_R1.fq.gz PKAS04_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS04_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS05_124_unmapped_R1.fq.gz PKAS05_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS05_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS06_124_unmapped_R1.fq.gz PKAS06_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS06_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS07_124_unmapped_R1.fq.gz PKAS07_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS07_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS08_124_unmapped_R1.fq.gz PKAS08_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS08_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS09_124_unmapped_R1.fq.gz PKAS09_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS09_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS10_124_unmapped_R1.fq.gz PKAS10_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS10_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS11_124_unmapped_R1.fq.gz PKAS11_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS11_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS12_124_unmapped_R1.fq.gz PKAS12_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS12_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS13_124_unmapped_R1.fq.gz PKAS13_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS13_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS14_124_unmapped_R1.fq.gz PKAS14_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS14_124.bam
bwa mem -t 10 -M -R "@RG\tID:PKAS01_124\tPL:ILLUMINA" $INDEXTDIR PKAS15_124_unmapped_R1.fq.gz PKAS15_124_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PKAS15_124.bam

echo "---------------------------------------"
echo "Finsihed!"
```


### Get mapping quality

File = 11_Map_Stats_pk_direct.pbs 
Version(s) = 38.90 (BBMap), 1.12 (samtools), 1.8.0_171 (java) & 0.6.3 (sambamba)

samtools was used to pipe the bam files into [BBMap](https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbmap-guide/), to get statisitcs on the alignment to the different genomes.
Both [java](https://www.java.com/en/) and [sambamba](https://lomereiter.github.io/sambamba/) are dependencies for BBmap.

Samtools view arguments
  • h - Include header in output. 

```{R,evalF}
#!/bin/bash
#PBS -N Map_Stats
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap, samtools & sambamba, & load java"
export Path=$PATH:/home/jwestaway/pk_pipeline/tools/bbmap
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/  
export PATH=$PATH:/usr/local/miniconda3/pkgs/quast-5.0.2-py37pl526hb5aa323_2/lib/python3.7/site-packages/quast_libs/sambamba
module load java/1.8.0_171

echo "---------------------------------------"
echo 'Alignment - direct to Pk'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/direct_alignment/
PILEUP="/home/jwestaway/pk_pipeline/tools/bbmap/pileup.sh"

echo "---------------------------------------"
echo 'Exectue samtools & bbmap for direct alignment'
for i in *_124.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%_124.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Hg'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/sortedbam/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *_124.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%_124.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Pk post Hg removal'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/pk_alignment/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *_124.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%_124.bam}.mapstats
done 

echo "---------------------------------------"
echo "Finsihed!"
```

### Get read depth

File = 12_Read_depth.pbs
Version(s) = 1.12 (samtools)

[samtools depth](http://www.htslib.org/doc/samtools-depth.html) was used to get read depth for each of the alignments. 
The command requires a BED file as part of the input. This can be created using the indexed genomes using the .fai files:

`awk 'BEGIN {FS="\t"}; {print $1 FS "0" FS $2}' GRCh38d1_noalt.fa.fai > GRCh38d1_noalt.fa.bed`
`awk 'BEGIN {FS="\t"}; {print $1 FS "0" FS $2}' strain_A1_H.1.Icor.fasta.fai > strain_A1_H.1.Icor.fasta.bed`

If a .fai file has not been created, `samtools faidx $fasta` can be used to create one.

Samtools depth arguments
  • a - Output all positions (including those with zero depth). 
  • b - Compute depth at list of positions or regions in specified BED FILE. 
  • f - Use the BAM files specified in the FILE (a file of filenames, one file per line).

```{R, eval=F}
#!/bin/bash
#PBS -N S_read_depth
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'DIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/direct_alignment/
BED='/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed'

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 10 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 10 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o SS_direct_depth_summary.depth

echo "---------------------------------------"
echo 'INDIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/pk_alignment/

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 10 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 10 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o SS_indirect_depth_summary.depth

echo "---------------------------------------"
echo "Finsihed!"
```

##################################################################################################################################

## Updated Sanger dataset

## FastQC

File = 01_QC.pbs 
Version(s) = 0.10.1

```{r, eval=F}
#!/bin/bash
#PBS -N fastqc
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=40gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to fastqc"
export PATH=$PATH:/usr/local/FastQC

echo "---------------------------------------"
echo "Change to current working directory"
cd pk_pipeline

echo "---------------------------------------"
echo "Set environment variable"
INPUTDIR="Sanger_100/pk_data/subset/"
OUTDIR="Sanger_100/outputs/fastqc/"
mkdir $OUTDIR

echo "---------------------------------------"
echo "Execute fastqc"
fastqc -t 10 -o $OUTDIR $INPUTDIR/*.fastq.gz

echo "---------------------------------------"
echo "Finsihed!"
```

## MultiQC 

File = 02_MultiQC.pbs
Version(s) = 0.1.9

```{r, eval=F}
#!/bin/bash
#PBS -N multiqc
#PBS -j oe
#PBS -m ae
#PBS -l select=1:ncpus=10:mem=40gb
#PBS -l walltime=04:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to singularity"
export PATH=$PATH:/usr/local/singularity/latest/bin/

echo "---------------------------------------"
echo "Set environment variable"
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_100/outputs/fastqc/"

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec /home/jwestaway/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

## Trimming 

File = 03_Trim.pbs
Version(s) = 3.1.0 (singularity), 0.6.4 (trim-galore) & 20171222 (parallel)


```{r, eval=F}
#!/bin/bash
#PBS -N trim
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=20
#PBS -l mem=40gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export paths and load modules"
export PATH=$PATH:/usr/local/singularity/latest/bin
export PATH=$PATH:/usr/local/parallel_20171222/bin/

echo "---------------------------------------"
echo 'Change to current working directory' 
cd pk_pipeline

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="Sanger_100/outputs/trimmed"
INPUTDIR="Sanger_100/pk_data/subset"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Exectue trim_galore for quality and adapter trimming'
parallel -j15 --xapply singularity exec ~/pk_pipeline/tools/singularity/trim-galore_0.6.4.sif trim_galore --illumina --paired --fastqc -o $OUTDIR ::: $INPUTDIR/*1.fastq.gz ::: $INPUTDIR/*2.fastq.gz

echo "---------------------------------------"
echo "Finsihed!"
```

## MultiQC on trimmed reads

File = 04_MultiQC_trimmed.pbs
Version(s) = 0.1.9

```{R, eval=F}
#!/bin/bash
#PBS -N multiqc
#PBS -j oe
#PBS -m ae
#PBS -l select=1:ncpus=10:mem=40gb
#PBS -l walltime=04:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to singularity"
export PATH=$PATH:/usr/local/singularity/latest/bin/

echo "---------------------------------------"
echo "Set environment variable"
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_100/outputs/fastqc/"

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec /home/jwestaway/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

# Mapping/Alignment

### Direct Pk Alignment

File = 07_Alignment_pk_direct.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Align_pk_Sanger
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 


echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_100/outputs/direct_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Change to working directory' 
cd pk_pipeline/Sanger_100/outputs/trimmed

echo "---------------------------------------"
echo 'Exectue bwa and samtools'
for i in *_val_1.fq.gz
do
bwa mem -t 15 -M -R "@RG\tID:${i%_1_val_1.fq.gz}\tPL:ILLUMINA" $INDEXTDIR $i ${i%_1_val_1.fq.gz}_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/${i%_1_val_1.fq.gz}.bam
done 

echo "---------------------------------------"
echo 'Finished!'
```

### Mapping to host genome first

#### Alignment and sort to BAM 

File = 08_Align_to_hg.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

```{R, eval=F}
#!/bin/bash
#PBS -N Align_host
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=200gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/sortedbam/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/human/GRCh38d1_noalt.fa"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Change to working directory' 
cd pk_pipeline/Sanger_100/outputs/trimmed/

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'
echo "---------------------------------------"
for i in *_val_1.fq.gz
do
bwa mem -t 20 -M -R "@RG\tID:${i%_1_val_1.fq.gz}\tPL:ILLUMINA" $INDEXTDIR $i ${i%_1_val_1.fq.gz}_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/${i%_1_val_1.fq.gz}.bam
done 

echo "---------------------------------------"
echo 'Finished!'
```

#### Get unaligned read pairs and fastqs
File = 09_Fastq_from_hg_align.pbs
Version = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N fastq_from_hg_align
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/outputs/alignment/hg_removed_alignment/sortedbam/

echo "---------------------------------------"
echo 'Set environment vars for bam file step'
OUTDIR="/home/jwestaway/pk_pipeline/outputs/alignment/hg_removed_alignment/unaligned_pairs/"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Get un-aligned reads (Pk reads)'
for i in *_124.bam
do
samtools -@ 15 view -b -f 12 -F 256 -o $OUTDIR/${i%_124.bam}.unaligned.bam $i
done 

echo "---------------------------------------"
echo 'Set environment vars for fastq file step'
cd $OUTDIR
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/human/GRCh38d1_noalt.fa"
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/hg_rem_fastq/"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Get fastqs from unaligned pk read pairs'
for i in *.unaligned.bam
do
samtools bam2fq -@ 15 -1 $OUTDIR/${i%.unaligned.bam}_unmapped_R1.fq.gz -2 $OUTDIR/${i%.unaligned.bam}_unmapped_R2.fq.gz -N --reference $INDEXTDIR -s /dev/null $i
 
done 
echo "---------------------------------------"
echo "Finsihed!"
```

#### Alignment to Pk reference genome

File = 10_Alignment_hg_removed.pbs
Version = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Align_Pk_no_host
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au
echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/hg_rem_fastq/

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/pk_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'
for i in *_unmapped_R1.fq.gz
do
bwa mem -t 15 -M -R "@RG\tID:${i%_unmapped_R1.fq.gz}\tPL:ILLUMINA" $INDEXTDIR $i ${i%_unmapped_R1.fq.gz}_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/${i%_unmapped_R1.fq.gz}.bam
done 

echo "---------------------------------------"
echo "Finsihed!"
```

### Get mapping quality

File = 11_Map_Stats_pk_direct.pbs 
Version(s) = 38.90 (BBMap) & 1.12 (samtools)

bbmap was run on all alignments (direct to the Pk, to the Hg, and to Pk post Hg removal) within the same submission.

```{R,eval=F}
#!/bin/bash
#PBS -N Map_Stats
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=4:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export Path=$PATH:/home/jwestaway/pk_pipeline/tools/bbmap
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/  
export PATH=$PATH:/usr/local/miniconda3/pkgs/quast-5.0.2-py37pl526hb5aa323_2/lib/python3.7/site-packages/quast_libs/sambamba
module load java/1.8.0_171

echo "---------------------------------------"
echo 'Alignment - direct to Pk'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/direct_alignment/
PILEUP="/home/jwestaway/pk_pipeline/tools/bbmap/pileup.sh"

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Hg'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/sortedbam/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Pk post Hg removal'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/pk_alignment/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo "Finsihed!"
```

### Get read depth

File = 12_Read_depth.pbs
Version(s) = 1.12 (samtools)

```{R, eval=F}
#!/bin/bash
#PBS -N S100_read_depth
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'DIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/direct_alignment/
BED='/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed'

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 10 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 10 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o S100_direct_depth_summary.depth

echo "---------------------------------------"
echo 'INDIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/pk_alignment/

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 10 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 10 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o S100_indirect_depth_summary.depth

echo "---------------------------------------"
echo "Finsihed!"
```


##################################################################################################################################

## ZB dataset


## FastQC

File = 01_QC.pbs 
Version(s) = 0.10.1

```{r, eval=F}
#!/bin/bash
#PBS -N fastqc
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=40gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to fastqc"
export PATH=$PATH:/usr/local/FastQC

echo "---------------------------------------"
echo "Change to current working directory"
cd pk_pipeline

echo "---------------------------------------"
echo "Set environment variable"
INPUTDIR="ZB_100/pk_data/subset/"
OUTDIR="ZB_100/outputs/fastqc/"
mkdir $OUTDIR

echo "---------------------------------------"
echo "Execute fastqc"
fastqc -t 10 -o $OUTDIR $INPUTDIR/*.fq.gz

echo "---------------------------------------"
echo "Finsihed!"
```

## MultiQC 

File = 02_MultiQC.pbs
Version(s) = 0.1.9

```{r, eval=F}
#!/bin/bash
#PBS -N multiqc
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=40gb
#PBS -l walltime=04:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to singularity"
export PATH=$PATH:/usr/local/singularity/latest/bin

echo "---------------------------------------"
echo "Set environment variable"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/fastqc"

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec /home/jwestaway/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

## Trimming 

File = 03_Trim.pbs
Version(s) = 3.1.0 (singularity), 0.6.4 (trim-galore) & 20171222 (parallel)

```{r, eval=F}
#!/bin/bash
#PBS -N trim
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export paths and load modules"
export PATH=$PATH:/usr/local/singularity/latest/bin
export PATH=$PATH:/usr/local/parallel_20171222/bin/

echo "---------------------------------------"
echo 'Change to current working directory' 
cd pk_pipeline

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="ZB_100/outputs/trimmed"
INPUTDIR="ZB_100/pk_data/subset"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Exectue trim_galore for quality and adapter trimming'
parallel -j20 --xapply singularity exec ~/pk_pipeline/tools/singularity/trim-galore_0.6.4.sif trim_galore --illumina --paired --fastqc -o $OUTDIR ::: $INPUTDIR/*1.fq.gz ::: $INPUTDIR/*2.fq.gz

echo "---------------------------------------"
echo "Finsihed!"
```

## MultiQC on trimmed reads

File = 04_MultiQC_trimmed.pbs
Version(s) = 0.1.9

```{R, eval=F}
#!/bin/bash
#PBS -N multiqc
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=40gb
#PBS -l walltime=04:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to multiqc"
export PATH=$PATH:/usr/local/singularity/latest/bin

echo "---------------------------------------"
echo "Set environment variable"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/trimmed"

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec ~/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

# Mapping/Alignment

### Direct Pk Alignment

File = 07_Alignment_pk_direct.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Align_pk_ZB
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=200gb
#PBS -l walltime=72:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 


echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/trimmed

echo "---------------------------------------"
echo 'Exectue bwa and samtools'
for i in *_val_1.fq.gz
do
bwa mem -t 15 -M -R "@RG\tID:${i%_1_val_1.fq.gz}\tPL:ILLUMINA" $INDEXTDIR $i ${i%_1_val_1.fq.gz}_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/${i%_1_val_1.fq.gz}.bam
done 

echo "---------------------------------------"
echo 'Finished!'
```

### Mapping to host genome first

#### Alignment and sort to BAM 

Aligning to the Hg has proven to be more compute intensive than I had anticipated. As a result, I had to split the jobs and run a PBS script for each sample.
To do this I created a template script and then used some bash commands to replicate this script for each sample by substituting the sample name.

> ls *_1_val_1.fq.gz | sed 's/_1_val_1.fq.gz//' > sample_names.txt

> for i in $(cat sample_names.txt)
> do
> sed s/SAMPLE/$i/g Pk_alignment_template.pbs > ${i}.pbs
> done

The resulting files can be found in 08_Align_to_hg, and an example is given below.

File = 034_Align_to_hg.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

```{R, eval=F}
#!/bin/bash
#PBS -N Align_host
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=20gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/sortedbam/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/human/GRCh38d1_noalt.fa"

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/trim_test/outputs/trimmed/

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'
echo "---------------------------------------"

bwa mem -t 10 -M -R "@RG\tID:PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4\tPL:ILLUMINA" $INDEXTDIR PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_1_val_1.fq.gz PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.bam

echo "---------------------------------------"
echo 'Finished!'
```

#### Get unaligned read pairs and fastqs
File = 09_Fastq_from_hg_align.pbs
Version = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N fastq_from_hg_align
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=100gb
#PBS -l walltime=4:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/sortedbam/

echo "---------------------------------------"
echo 'Set environment vars for bam file step'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/unaligned_pairs/"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Get un-aligned reads (Pk reads)'
for i in *.bam
do
samtools view -@ 15 -b -f 12 -F 256 -o $OUTDIR/${i%.bam}.unaligned.bam $i 
done 

echo "---------------------------------------"
echo 'Set environment vars for fastq file step'
cd $OUTDIR
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/human/GRCh38d1_noalt.fa"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/hg_rem_fastq/"
mkdir -p $OUTDIR

echo "---------------------------------------"
echo 'Get fastqs from unaligned pk read pairs'
for i in *.unaligned.bam
do
samtools bam2fq -@ 15 -1 $OUTDIR/${i%.unaligned.bam}_unmapped_R1.fq.gz -2 $OUTDIR/${i%.unaligned.bam}_unmapped_R2.fq.gz -N --reference $INDEXTDIR -s /dev/null $i
 
done 
echo "---------------------------------------"
echo "Finsihed!"
```

#### Alignment to Pk reference genome

I again ran this alignment by sample for faster turnover, creating scripts witht the below syntax:

> ls *_1_val_1.fq.gz | sed 's/_1_val_1.fq.gz//' > sample_names.txt

> for i in $(cat sample_names.txt)
> do
> sed s/SAMPLE/$i/g Pk_alignment_template.pbs > ${i}.pbs
> done

The scripts can be found in 10_Alignment_hg_removed, and example is given below:

File = PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.pbs
Version = 0.7.10 (bwa) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Align_Pk_bwa
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=20gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au
echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/hg_rem_fastq/

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/pk_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'

bwa mem -t 10 -M -R "@RG\tID:PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4\tPL:ILLUMINA" $INDEXTDIR PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_unmapped_R1.fq.gz PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.bam

echo "---------------------------------------"
echo "Finsihed!"

```

### Get mapping quality

File = 11_Map_Stats_pk_direct.pbs 
Version(s) = 38.90 (BBMap), 1.12 (samtools), 1.8.0_171 (java) & 0.6.3 (sambamba)

```{R,eval=F}
#!/bin/bash
#PBS -N Map_Stats
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=4:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export Path=$PATH:/home/jwestaway/pk_pipeline/tools/bbmap
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/  
export PATH=$PATH:/usr/local/miniconda3/pkgs/quast-5.0.2-py37pl526hb5aa323_2/lib/python3.7/site-packages/quast_libs/sambamba
module load java/1.8.0_171

echo "---------------------------------------"
echo 'Alignment - direct to Pk'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment/
PILEUP="/home/jwestaway/pk_pipeline/tools/bbmap/pileup.sh"

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Hg'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/sortedbam/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Pk post Hg removal'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/pk_alignment/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo "Finsihed!"
```

### Get read depth

File = 12_Read_depth.pbs
Version(s) = 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N ZB_read_depth
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'DIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment/
BED='/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed'

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 20 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 20 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o ZB_redo_direct_depth_summary.depth

echo "---------------------------------------"
echo 'INDIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/pk_alignment/

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 20 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 20 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o ZB_redo_indirect_depth_summary.depth

echo "---------------------------------------"
echo "Finsihed!"
```


############################################################################################################

# Comparisons for mapping

- Here we make comparisons on the number of reads being obtained from the three datasets, the number of reads mapping and the read depth at different positions along the Pk genome.

## Mapstats

Can concatenate output *.mapstats files within a given directory, and select only the relevant information (including the file/sample name) with:

`tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' > S100_HGR_summary.mapstats`

Outputs = dataset_alignment_summary.mapstats
Example = SS_PKD_summary.mapstats = sanger subset & Pk direct alignment

The PBS script below colates all the mapstats outputs for a given alignment and converts them into a two-column csv file.

**NB.** If you run the above you need to alter the wildcard input (*mapstats) below or change the filename above.
Can concatenate output *.mapstats files within a given directory, selecting only the relevant information (including the file/sample name), and then wrangle it to be easier to handle in R with:
`tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > test.csv`


File = Sum_mapstats.pbs
Version(s) = 38.90 (BBMap) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N BBMap_sum
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=10gb
#PBS -l walltime=1:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Create output directory for all files"
OUTDIR="/home/jwestaway/pk_pipeline/analysis/bbmap_summary/"
mkdir $OUTDIR

echo "---------------------------------------"
echo "SS"

echo "Direct to Pk"
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/direct_alignment/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/SS_PKD_summary_mapstats.csv

echo "Indirect to Hg"
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/sortedbam/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/SS_HGA_summary_mapstats.csv

echo "Indirect to Pk"
cd /home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/hg_removed_alignment/pk_alignment/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/SS_HGR_summary_mapstats.csv

echo "---------------------------------------"
echo "S_100"

echo "Direct to Pk"
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/direct_alignment/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/S100_PKD_summary_mapstats.csv

echo "Indirect to Hg"
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/sortedbam/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/S100_HGA_summary_mapstats.csv

echo "Indirect to Pk"
cd /home/jwestaway/pk_pipeline/Sanger_100/outputs/hg_removed_alignment/pk_alignment/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/S100_HGR_summary_mapstats.csv

echo "---------------------------------------"
echo "ZB_100"

echo "Direct to Pk"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/ZB_PKD_summary_mapstats.csv

echo "Indirect to Hg"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/sortedbam/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/ZB_HGA_summary_mapstats.csv

echo "Indirect to Pk"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/hg_removed_alignment/pk_alignment/
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > $OUTDIR/ZB_HGR_summary_mapstats.csv

echo "---------------------------------------"
echo "Finsihed!"
```
**NB.** Downloaded these output files manually to desktop for subsequent exploratory analysis in R.

## Analysis of mapstats outputs in R

**Look at Mapping_Report**


### Why are some samples losing so many reads to the Hg before Pk mapping?

**Could be duplicates.**

Take the samples that are losing the most reads from SS and ZB datasets direct alignment (S100 doesn't have any visibly significant changes), remove duplicates from the aligned BAM files and re-run some of the above stats and plots.

########################################################################################################################

## Remove duplicates

Use files that have been aligned (direct).

File: Remove_dups.pbs
Version(s): 1.12 (samtools)

[Marking duplicates](http://www.htslib.org/doc/samtools-markdup.html) requires that the input file is both sorted by position and NOT name, and has mate coordinates.

```{R,eval=F}
#!/bin/bash
#PBS -N Duplicate_analysis
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=20gb
#PBS -l walltime=1:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/samtools

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/analysis/
OUTDIR="/home/jwestaway/pk_pipeline/analysis/remove_duplicates"
mkdir $OUTDIR
SS_File="/home/jwestaway/pk_pipeline/Sanger_Subset/outputs/alignment/direct_alignment"
ZB_File="/home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment"

echo "---------------------------------------"
echo 'Exectue samtools fixmate to give MC and ms tags'
samtools fixmate -m $SS_File/PKAS13_124.bam $OUTDIR/PKAS13_124_FIX.bam
samtools fixmate -m $ZB_File/PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.bam $OUTDIR/PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4_FIX.bam 

echo "---------------------------------------"
echo 'Exectue samtools to sort by coordinates'
samtools sort -o $OUTDIR/PKAS13_124_SORTED.bam $OUTDIR/PKAS13_124_FIX.bam
samtools sort -o $OUTDIR/PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4_SORTED.bam $OUTDIR/PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4_FIX.bam

echo "---------------------------------------"
echo 'Exectue samtools markdup to mark and remove duplicates'
samtools markdup -r $OUTDIR/PKAS13_124_SORTED.bam $OUTDIR/PKAS13_124_DUPS.bam
samtools markdup -r $OUTDIR/PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4_SORTED.bam $OUTDIR/PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4_DUPS.bam

echo "---------------------------------------"
echo "Finsihed!"
```

## Get mapstats and create a summary csv file

File = dups_mapstats.pbs
Version(s) = Version(s) = 38.90 (BBMap), 1.12 (samtools), 1.8.0_171 (java) & 0.6.3 (sambamba)

```{R,eval=F}
#!/bin/bash
#PBS -N Duplicate_mapstats_csv
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=5
#PBS -l mem=20gb
#PBS -l walltime=1:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export Path=$PATH:/home/jwestaway/pk_pipeline/tools/bbmap
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/  
export PATH=$PATH:/usr/local/miniconda3/pkgs/quast-5.0.2-py37pl526hb5aa323_2/lib/python3.7/site-packages/quast_libs/sambamba
module load java/1.8.0_171

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/analysis/remove_duplicates
PILEUP="/home/jwestaway/pk_pipeline/tools/bbmap/pileup.sh"

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *_DUPS.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%_DUPS.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Create summary csv file'
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > DUPS_summary_mapstats.csv

echo "---------------------------------------"
echo "Finsihed!"
```

### Analyse pre and post-duplicate removals in R

File(s) = DUPS_summary_mapstats.csv
Version(s) = 1.3.0 (tidyverse), 1.2.1335 (RStudio) & 3.6.1 (R)

```{r,warning=F,message=F}
library(tidyverse)
```

Create a dataframe for ALL sample rows that had duplicates removed and plot a comparison (direct vs indirect coloured by Data and include sample names)

```{r}
DUPS <- read_csv("data/bbmap_summary/DUPS_summary_mapstats.csv", col_names = c("Variable", "Value")) %>%
  mutate(Variable = str_remove(Variable, "==> ")) %>% 
  filter(!grepl("mapstats", Variable)) %>% # data specific
  add_column(
    (read_csv("data/bbmap_summary/DUPS_summary_mapstats.csv", col_names = c("Variable", "Value")) %>% 
       mutate(Variable = str_remove(Variable, "==> ")) %>% 
       filter(grepl("mapstats", Variable)) %>% # data specific
       mutate(Variable = Variable) %>% 
       rbind(.,.,.,.,.,.,.,.,.,.,.,.) %>% # represents the number of variables
       arrange(desc(Variable)) %>% 
       mutate_if(is.character, as.factor) %>% 
       select(Variable) %>% 
       rename("ID" = Variable))) %>% 
  pivot_wider(names_from = Variable, values_from = Value) %>% 
  add_column(Data = "DUPS", Alignment = "Direct", Genome = "Pk") %>% 
  as.tibble(.name_repair = "universal") %>% 
  mutate(ID = str_replace(ID, "_124", "")) %>% 
  mutate(ID = str_replace(ID, "_124", "")) %>% 
  mutate(ID = str_replace(ID, "mapstats", "dups_removed"))
```

### Plot the mapped reads with the duplicate-removed samples included

```{r}
BBMAP %>% 
  rbind(DUPS) %>% 
  filter(Genome == "Pk") %>%
  ggplot() + 
  geom_col(aes(x = ID, y = Mapped.reads/1000000, colour = Data)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = "Samples", y= "Mapped reads (100K)") +
  facet_wrap(~Alignment)
```

### Plot just the samples that have had duplicates removed (with the originals included)

```{r}
DUPS %>% 
  rbind(
    (BBMAP %>% filter(Genome == "Pk" & (ID == "PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.mapstats" | ID == "PKAS13.mapstats")))) %>%
  mutate(ID = recode(ID, "PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.dups_removed" = "ZB_31_dups", 
                     "PKAS13.dups_removed" = "SS_13_dups", 
                     "PKAS13.mapstats" = "SS_13",
                     "PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.mapstats" = "ZB_31")) %>% 
  ggplot() + 
  geom_col(aes(x = ID, y = Mapped.reads/1000000, colour = Data)) +
  theme(axis.text.x = element_text(angle = 90), axis.ticks = element_blank()) +
  labs(x = "Samples", y= "Mapped reads (100K)") +
  facet_wrap(~Alignment)
```

### Compare direct alignment statistics for samples that have/haven't had duplicates removed

```{r}
DUPS %>% 
  rbind((BBMAP %>% 
           filter(Genome == "Pk" & (ID == "PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.mapstats" | ID == "PKAS13.mapstats")))) %>% 
  arrange(ID) %>% 
  select(ID, Alignment, Reads, Mapped.reads, Mapped.bases)
```

**DUPLICATES do not account for the loss in mapped reads after aligning to Hg.**
28% for SS.
55% for ZB.

### Prep data for IGV
Require:
 - reference.fasta
 - reference.fasta.fai
 - reference.gff
 - chromosome_sorted.bam
 - indexed_chromosome_sorted.bam.bai

[Helpful tutorial.](https://wikis.utexas.edu/display/bioiteam/Integrative+Genomics+Viewer+%28IGV%29+tutorial)


#### Index Pk genome to get .fai file

If `read depth` with samtools has been run you can also just use the sorted.bam and bam.fai outputs.

File = Index_for_fai.pbs
Version(s) = 1.12 (samtools)

```{R,eval=F```
#!/bin/bash
#PBS -N Idex_for_fai
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=20gb
#PBS -l walltime=4:00:00
#PBS -M jacob.westaway@menzies.edu.au


echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/samtools 

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd "/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/"


echo "---------------------------------------"
echo 'Exectue samtools index'

samtools faidx fasta/strain_A1_H.1.Icor.fasta -o strain_A1_H.1.Icor.fasta.fai

echo "---------------------------------------"
echo "Finsihed!"
```

#### Sort and index bam alignment files

File = sort_index_bam.pbs 
Version(s) = 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Sort_index
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=10
#PBS -l mem=20gb
#PBS -l walltime=4:00:00
#PBS -M jacob.westaway@menzies.edu.au


echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/samtools 

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/IGV


echo "---------------------------------------"
echo 'Exectue samtools for ZB'
samtools sort PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.bam > PK_SB_DNA_031_sorted.bam
samtools index PK_SB_DNA_031_sorted.bam 

echo "---------------------------------------"
echo 'Exectue samtools for SS'

samtools sort PKAS13_124.bam > PKAS13_sorted.bam 
samtools index PKAS13_sorted.bam 


echo "---------------------------------------"
echo "Finsihed!"
```

############################################################################################################

# Comparisons for read depth using samtools depth

## Convert depth files to tsv (mv *.depth *.tsv) and read into R.

## Analysis of Read Depth outputs in R

**Look at Mapping_Report**


# Comparisons for read depth using IGV
Download *sorted.bam *bam.bai files from 12_Read_depth.pbs to be used in IGV or tablet.

###################################################################################################

# Trying bowtie2 alignment to Hg

Combining bowtie2 for the Hg alignment with bwa for the Pk alignment may improve the mapping.

## Index with bowtie2

bowtie2 requires there indexed files labled a specific way (different to bwa).

File: 01_bowtie2_index.pbs
Version(s): 2.2.4 (bowtie2)

```{R,eval=F}
#!/bin/bash
#PBS -N Bowtie_index
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bowtie and samtools"
export PATH=$PATH:/usr/local/bowtie2-2.2.4  

echo "---------------------------------------"
echo "Change working directory"
cd /home/jwestaway/pk_pipeline/ZB_100/bowtie2/indexed_genomes

echo "---------------------------------------"
echo "INDEX PK WITH BOWTIE2"
bowtie2-build /home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta PK

echo "---------------------------------------"
echo "INDEX HG WITH BOWTIE2"
bowtie2-build /home/jwestaway/pk_pipeline/ref_genomes/human/GRCh38d1_noalt.fa  HG

echo "---------------------------------------"
echo 'Finished!'
```

## Align to Hg and get fastq for Pk alignment

Aligning to the Hg has proven to be more compute intensive than I had anticipated. As a result, I had to split the jobs and run a PBS script for each samples.
To do this I created a template script and then used some bash commands to replicate this script for each sample by substituting the sample name in.

> ls *_1_val_1.fq.gz | sed 's/_1_val_1.fq.gz//' > sample_names.txt

> for i in $(cat sample_names.txt)
> do
> sed s/SAMPLE/$i/g Pk_alignment_template.pbs > ${i}.pbs
> done

The resulting scripts are found in 02_bowtie2_align_Hg, and below is an example for a single sample.

File: 034_bowtie2_align_Hg.pbs
Version(s): 2.2.4 (bowtie2) & 1.12 (samtools)

bowtie2 arguments
  • -p - threads
  • -x - path to indexed genome

```{R,eval=F}
#!/bin/bash
#PBS -N Bowtie_Hg_align
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=20gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bowtie and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bowtie2-2.2.4  

echo "---------------------------------------"
echo "ALIGN TO HG GENOME USING BOWTIE"

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/sorted_bam"
INDEXTDIR="/home/jwestaway/pk_pipeline/ZB_100/bowtie2/indexed_genomes/"

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/trim_test/outputs/trimmed/

echo "---------------------------------------"
echo 'Exectue bowtie2 and samtools to align files and convert to bam format'

bowtie2 -p 10 -x $INDEXTDIR/HG -1 PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_1_val_1.fq.gz -2 PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_2_val_2.fq.gz  | samtools view -u -S - | samtools sort -n -o $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.bam

echo "---------------------------------------"
echo "FASTQ FROM HG ALIGNMENT"

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/sorted_bam

echo "---------------------------------------"
echo 'Set environment vars for bam file step'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/unaligned_pairs/"

echo "---------------------------------------"
echo 'Get un-aligned reads (Pk reads)'

samtools view -@ 10 -b -f 12 -F 256 -o $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.unaligned.bam PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.bam 

echo "---------------------------------------"
echo 'Set environment vars for fastq file step'
cd $OUTDIR
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/hg_rem_fastq/"

echo "---------------------------------------"
echo 'Get fastqs from unaligned pk read pairs'

samtools bam2fq -@ 10 -1 $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_unmapped_R1.fq.gz -2 $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_unmapped_R2.fq.gz -N --reference $INDEXTDIR -s /dev/null PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.unaligned.bam

echo "---------------------------------------"
echo 'Finished!'
```

## Pk alignment post-bowtie2

The Pk alignment was also done by sample.

> ls *_1_val_1.fq.gz | sed 's/_1_val_1.fq.gz//' > sample_names.txt

> for i in $(cat sample_names.txt)
> do
> sed s/SAMPLE/$i/g Pk_alignment_template.pbs > ${i}.pbs
> done

The scripts can be found in 03_Pk_alignment, and an example is given below.

File = PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.pbs
Version(s) = 0.7.10 (bwa) & 1.12 (samtools)

```{R, eval=F}
#!/bin/bash
#PBS -N Align_Pk_bowtie2
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=20gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au
echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/hg_rem_fastq/

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/Pk_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'

bwa mem -t 10 -M -R "@RG\tID:PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4\tPL:ILLUMINA" $INDEXTDIR PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_unmapped_R1.fq.gz PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4_unmapped_R2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.bam

echo "---------------------------------------"
echo "Finsihed!"
```

## Map stats and read depth from post-bowtie2 Pk alignment 

File = Map_Stats.pbs
Version(s) = 38.90 (BBMap), 1.12 (samtools), 1.8.0_171 (java) & 0.6.3 (sambamba)

```{R, eval=F}
#!/bin/bash
#PBS -N Map_Stats_ZB
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=12:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export Path=$PATH:/home/jwestaway/pk_pipeline/tools/bbmap
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/  
export PATH=$PATH:/usr/local/miniconda3/pkgs/quast-5.0.2-py37pl526hb5aa323_2/lib/python3.7/site-packages/quast_libs/sambamba
module load java/1.8.0_171

echo "---------------------------------------"
echo 'Set env variables'
PILEUP="/home/jwestaway/pk_pipeline/tools/bbmap/pileup.sh"

echo "---------------------------------------"
echo 'Alignment - to Hg'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/sorted_bam/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Alignment - to Pk post Hg removal'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/Pk_alignment/

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 15 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo "Finsihed!"
```
File = Read_depth.pbs
Version(s) = 1.12 (samtools)

```{R, eval=F}
#!/bin/bash
#PBS -N ZB_read_depth
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'Set env variables'
BED='/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed'

echo "---------------------------------------"
echo 'INDIRECT ALIGNMENT'

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/bowtie2/Hg_alignment/Pk_alignment/

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 15 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 15 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o ZB_indirect_depth_summary.depth

echo "---------------------------------------"
echo "Finsihed!"
```

###################################################################################################

# Comparing our samples to those in previous studies

To get an idea of how our samples stack up against previous sucessful studies we have downloaded samples from NCBI and run them through the same direct alignment outlined above.
We can then calculate read depth samtools and plot the depth of these samples with our mapped datasets to see how they comapre.
The first step is downloading samples from NCBI.

Link to sample list: https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-019-46398-z/MediaObjects/41598_2019_46398_MOESM1_ESM.pdf

Samples: ERR985372, ERR985373, ERR985385, ERR985386

## Download and convert previous data files to paired fastq files
> wget https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos3/sra-pub-run-21/ERR2762860/ERR2762860.1
> /usr/local/sratoolkit.2.8.2-1-centos_linux64/bin/fastq-dump -F --split-files ERR2762860.1

fastq-dump arguments
  • --split-files - split into forward and reverse files
  • -F - defline contains only original sequence name (without there will be downstream during the alignment)


## Run QC, trimming and direct Pk alignment, and calculate the read depth

File: Data_comparison.pbs
Version(s): 0.7.10 (bwa), 3.1.0 (singularity), 0.6.4 (trim-galore), 20171222 (parallel), 0.1.9 (MultiQC), 0.10.1 (FastQC) & 1.12 (samtools)

```{R,eval=F}
#!/bin/bash
#PBS -N Comparison
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"


echo "---------------------------------------"
echo 'QC'

echo "Export path to fastqc and singularity"
export PATH=$PATH:/usr/local/FastQC
export PATH=$PATH:/usr/local/singularity/latest/bin

echo "Change to current working directory"
cd /home/jwestaway/pk_pipeline/previous_pk_data

echo "Set environment variable"
INPUTDIR="pk_data/"
OUTDIR="outputs/fastqc/"
mkdir $OUTDIR

echo "Execute fastqc"
fastqc -t 15 -o $OUTDIR $INPUTDIR/*.fastq

echo "Execute multiqc in OUTDIR using singularity"
cd $OUTDIR
singularity exec /home/jwestaway/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo 'QC FINISHED'



echo "---------------------------------------"
echo 'Trimming'

echo "Export path to parallel"
export PATH=$PATH:/usr/local/parallel_20171222/bin/

echo 'Change to current working directory' 
cd /home/jwestaway/pk_pipeline/previous_pk_data

echo 'Set environment vars'
OUTDIR="outputs/trimmed"
INPUTDIR="pk_data/"
mkdir -p $OUTDIR

echo 'Exectue trim_galore for quality and adapter trimming'
parallel -j15 --xapply singularity exec ~/pk_pipeline/tools/singularity/trim-galore_0.6.4.sif trim_galore --illumina --paired --fastqc -o $OUTDIR ::: $INPUTDIR/*1.fastq ::: $INPUTDIR/*2.fastq

echo 'Trimming FINISHED'



echo "---------------------------------------"
echo 'QC'

echo "Change to previous output directory"
cd $OUTDIR

echo "Execute multiqc using singularity"
singularity exec ~/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo 'QC FINISHED'



echo "---------------------------------------"
echo 'Alignment'

echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/previous_pk_data/outputs/direct_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir -p $OUTDIR

echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/previous_pk_data/outputs/trimmed

echo 'Exectue bwa and samtools'
for i in *_val_1.fq
do
bwa mem -t 15 -M -R "@RG\tID:${i%_1_val_1.fq}\tPL:ILLUMINA" $INDEXTDIR $i ${i%_1_val_1.fq}_2_val_2.fq | samtools view -u -S - | samtools sort -n -o $OUTDIR/${i%_1_val_1.fq}.bam
done 

echo 'ALIGNMENT FINISHED'



echo "---------------------------------------"
echo 'Read Depth'

echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/previous_pk_data/outputs/direct_alignment/
BED='/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed'

echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 15 $i > ${i%.bam}.sorted.bam
done 

echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 15 $i 
done 

echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o ZB_direct_depth_summary.depth

echo 'READ DEPTH FINISHED'

echo "---------------------------------------"
echo 'PBS SCRIPT FINISHED'
```

 
############################################################################################################################
# Exploratory Analysis in R

File = Mapping_Report.Rmd (local)
Version(s) = 1.3.0 (tidyverse), 1.3.1 (readxl), 1.2.1335 (RStudio) & 3.6.1 (R)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'C:/Users/Jacob/Desktop/Menzies/Knowlesi/Pipeline/Pk_Pipeline/')
library(tidyverse)
library(janitor)
```

# About 

This report briefly goes through some of the comparisons we have made over the last couple of months to determine what might be the best combination of data (sample preperationa) and alignment type. In brief, we ran three datasets: the initial datset provided by Matt, data from Sanger and data from ZB. 
We tried aligning directly to the Pk genome (with *bwa*), and indirectly via removal of human contamination (with *bwa*/*bowtie2*). We ran mapping statistics (*bbmap*) and read depth calculations (*samtools*) on this data to get the number of reads aligning and the depth of reads at each position along the Pk genome. We also imported some of this data into *IGV*/*tablet* to do additonal visual comparisons, and downloaded some data from a previous study provided by Ernest to see how our best outputs (ZB's data) compared to a previously successful workflow. Lastly, we used metadata to explore the relationship between ZB's data and parasitemia.

From this work it seems safe to say that **ZB**'s data, along with aligning **directly** to the Pk genome with bwa, is the best approach.

Key terms/abbreviations:

 - ZB: data from Singapore/Zbynek Bozdech (truncated).
 - ZB_redo: data from Singapore/Zbynek Bozdech (not truncated).
 - SS: initial subset from Matt Grigg.
 - S100: data from Sanger.
 - Previous_Pk: data from a previous study provided by Ernest.
 - Direct: aligning/mapping to Pk genome without removal of human contamination.
 - Indirect: aligning/mapping to Pk after removal of human contamination.


The chunk below takes in the csv file specific to the dataset and type of alignment.
It then filters to remove the sample names, creating a datframe with only statistics/variables.
It then adds a column where we have filtered for the sample names, 'rbound' it to itself several times times and arranged it by samples names (so that each variable/statstic has an appropriate sample name in the adjaent column).
This resultant dataframe is in the appropriate long format, so then `pivot.wider()` is used to create a [tidy](https://tidyr.tidyverse.org/articles/tidy-data.html) dataframe for analysis (where the first column is the sample numbers and each additional column is a variable).

```{r,warning=F,message=F,include=F}
# Create a function to read in the BBmap data

bbmap_func <- function(file_path, grep_pattern, bbmap_data, alignment, genome){ 
read_csv(file_path, col_names = c("Variable", "Value")) %>%
  mutate(Variable = str_remove(Variable, "==> ")) %>% 
  filter(!grepl(grep_pattern, Variable)) %>% # data specific
  add_column(
    (read_csv(file_path, col_names = c("Variable", "Value")) %>% 
       mutate(Variable = str_remove(Variable, "==> ")) %>% 
       filter(grepl(grep_pattern, Variable)) %>% # data specific
       mutate(Variable = Variable) %>% 
       rbind(.,.,.,.,.,.,.,.,.,.,.,.) %>% # represents the number of variables
       arrange(Variable) %>% 
       mutate_if(is.character, as.factor) %>% 
       select(Variable) %>% 
       rename("ID" = Variable))) %>% 
  pivot_wider(names_from = Variable, values_from = Value) %>% 
  add_column(Data = bbmap_data, Alignment = alignment, Genome = genome)  %>% 
  as.tibble(.name_repair = "universal")
}


BBMAP <- 
# S_100 
bbmap_func("data/bbmap_summary/S100_PKD_summary_mapstats.csv", "ERR", "S100", "Direct", "Pk") %>%  # Direct Pk
  rbind(bbmap_func("data/bbmap_summary/S100_HGA_summary_mapstats.csv", "ERR", "S100", "Indirect", "Hg")) %>% # Indirect Hg
  rbind(bbmap_func("data/bbmap_summary/S100_HGR_summary_mapstats.csv", "ERR", "S100", "Indirect", "Pk")) %>% # Indirect Pk
  rbind(
# SS
(bbmap_func("data/bbmap_summary/SS_PKD_summary_mapstats.csv", "PKA", "SS", "Direct", "Pk") %>%  
  rbind(bbmap_func("data/bbmap_summary/SS_HGA_summary_mapstats.csv", "PKA", "SS", "Indirect", "Hg")) %>% 
  rbind(bbmap_func("data/bbmap_summary/SS_HGR_summary_mapstats.csv", "PKA", "SS", "Indirect", "Pk")) 
)) %>%
  rbind(
# ZB
(bbmap_func("data/bbmap_summary/ZB_PKD_summary_mapstats.csv", "PK_SB_DNA", "ZB", "Direct", "Pk") %>%  
  rbind(bbmap_func("data/bbmap_summary/ZB_HGA_summary_mapstats.csv", "PK_SB_DNA", "ZB", "Indirect", "Hg")) %>% 
  rbind(bbmap_func("data/bbmap_summary/ZB_HGR_summary_mapstats.csv", "PK_SB_DNA", "ZB", "Indirect", "Pk")) 
)) %>% 
  rbind(
# Previous Pk data
  bbmap_func("data/bbmap_summary/Previous_Pk_summary.csv", "ERR", "Previous_Pk", "Direct", "Pk")) %>%
  rbind(
# ZB redo
(bbmap_func("data/bbmap_summary/bowtie2_HGA_summary.csv", "PK_SB_DNA", "ZB_bowtie", "Indirect", "Hg") %>%  
  rbind(bbmap_func("data/bbmap_summary/bowtie2_HGR_summary.csv", "PK_SB_DNA", "ZB_bowtie", "Indirect", "Pk"))) %>% 
  rbind(bbmap_func("data/bbmap_summary/ZB_redo_HGA_summary_mapstats.csv", "PK_SB_DNA", "ZB_redo", "Indirect", "Hg")) %>% 
  rbind(bbmap_func("data/bbmap_summary/ZB_redo_HGR_summary_mapstats.csv", "PK_SB_DNA", "ZB_redo", "Indirect", "Pk")) %>% 
  rbind(bbmap_func("data/bbmap_summary/ZB_redo_PKD_summary_mapstats.csv", "PK_SB_DNA", "ZB_redo", "Direct", "Pk"))
  )
  
```

Below I group by the contigs and get the average read depth at each base using a function `read_depth_data()`. 
I then create a function that calculates the percentage of NA values, which represents the percentage of bases without any read depth.
These two functions are then nested inside a third funcion that uses these functions to read in the relevant data and wrangle it into an appropriate format.

```{r,warning=F,message=F,include=F,eval=F}
# Create a function that nests previously created functions for reading in data and wrangling it for depth and NA bp, and join data together with mapstats data

# define read depth function to get read depth per contig
read_depth_data <- function(file_path, dataset, alignment){
read_tsv(file_path, col_names = c("Contig", "Bases", "S01", "S02", "S03", "S04", "S05", "S06", "S07", "S08", "S09", "S10", "S11", "S12", "S13")) %>% 
  select(!Bases) %>% 
  filter(grepl("ordered", Contig)) %>% 
  group_by(Contig) %>% 
  summarise_all(mean) %>%
  t() %>% 
  as.data.frame() %>% 
  row_to_names(1) %>% 
  add_column(Data = dataset, Alignment = alignment) %>% 
  rownames_to_column("Sample")
}

# define base_pairs function to change names and get percentage of bases that are NA
base_pairs <- function(file_path, dataset, alignment){
read_tsv(file_path, col_names = c("Contig", "Bases", "S01", "S02", "S03", "S04", "S05", "S06", "S07", "S08", "S09", "S10", "S11", "S12", "S13")) %>% 
  select(!Bases) %>% 
  filter(grepl("ordered", Contig)) %>% 
  na_if(0) %>% 
  group_by(Contig) %>% 
  summarise_all(funs(sum(is.na(.))/length(.) * 100)) %>% 
  t() %>% 
  as.data.frame() %>% 
  row_to_names(1) %>% 
  add_column(Data = dataset, Alignment = alignment) %>% 
  rownames_to_column("Sample") %>% 
  rename("PKNH_01_NA_bases" = "ordered_PKNH_01_v2", "PKNH_02_NA_bases" ="ordered_PKNH_02_v2", 
         "PKNH_03_NA_bases" = "ordered_PKNH_03_v2", "PKNH_04_NA_bases" = "ordered_PKNH_04_v2", 
         "PKNH_05_NA_bases" = "ordered_PKNH_05_v2", "PKNH_06_NA_bases" = "ordered_PKNH_06_v2", 
         "PKNH_07_NA_bases" = "ordered_PKNH_07_v2", "PKNH_08_NA_bases" = "ordered_PKNH_08_v2", 
         "PKNH_09_NA_bases" = "ordered_PKNH_09_v2", "PKNH_10_NA_bases" = "ordered_PKNH_10_v2", 
         "PKNH_11_NA_bases" = "ordered_PKNH_11_v2", "PKNH_12_NA_bases" = "ordered_PKNH_12_v2", 
         "PKNH_13_NA_bases" = "ordered_PKNH_13_v2", "PKNH_14_NA_bases" = "ordered_PKNH_14_v2") %>% 
  mutate_at(c(2:15), as.character) %>% 
  mutate_at(c(2:15), as.numeric)
}

# nest the functions above in another function that combines this data the mapping data
create_sum_tab <- function(PATH, DATA, ALIGNMENT){
read_depth_data(PATH, DATA, ALIGNMENT) %>% # read in direct read depth data
  mutate_if(is.factor, as.character) %>% 
  mutate_at(grep("ordered", colnames(.)), as.numeric) %>% 
  add_column(Join = 1:nrow(.)) %>% # add column for joining with mapstats data
  left_join(
    (base_pairs(PATH, DATA, ALIGNMENT) %>% # read in direct NA base pair data and join
  mutate_if(is.factor, as.character) %>% 
  mutate_at(grep("ordered", colnames(.)), as.numeric) %>% 
  select(-Data, - Alignment))
  ) %>% 
  left_join( # join read depth and base NA data with map stat data via a new column called join
    (BBMAP %>% 
      filter(Genome != "Hg" & Data == DATA & Alignment == ALIGNMENT) %>%  
      mutate(ID = str_replace(ID,".mapstats", "")) %>% 
      add_column(Join = 1:nrow(.))
     ), by = "Join") %>% 
  select(-Data.y, -Alignment.y, -Join) %>% 
  rename("Data" = "Data.x", "Alignment" = "Alignment.x") %>%  
  relocate(ID, Data, Alignment)
}
 
     
Summary_Data <- create_sum_tab("data/read_depth/ZB_direct_depth_summary.tsv", "ZB", "Direct") %>% 
  rbind(create_sum_tab("data/read_depth/ZB_indirect_depth_summary.tsv", "ZB", "Indirect")) %>% 
  rbind(create_sum_tab("data/read_depth/SS_direct_depth_summary.tsv", "SS", "Direct")) %>% 
  rbind(create_sum_tab("data/read_depth/SS_indirect_depth_summary.tsv", "SS", "Indirect")) %>% 
  rbind(create_sum_tab("data/read_depth/S100_direct_depth_summary.tsv", "S100", "Direct")) %>% 
  rbind(create_sum_tab("data/read_depth/S100_indirect_depth_summary.tsv", "S100", "Indirect")) %>% 
  rbind(create_sum_tab("data/read_depth/previous_Pk_data.tsv", "Previous_Pk", "Direct")) %>% 
  slice(-c(83:91)) %>% 
  rbind(create_sum_tab("data/read_depth/ZB_bowtie2_depth_summary.tsv", "ZB_bowtie", "Indirect"))%>% 
  rbind(create_sum_tab("data/read_depth/ZB_redo_direct_depth_summary.tsv", "ZB_redo", "Direct")) %>% 
  rbind(create_sum_tab("data/read_depth/ZB_redo_indirect_depth_summary.tsv", "ZB_redo", "Indirect"))

Summary_Data <- Summary_Data %>% 
  rbind(create_sum_tab("data/read_depth/ZB_redo_direct_depth_summary.tsv", "ZB_redo", "Direct")) %>% 
  rbind(create_sum_tab("data/read_depth/ZB_redo_indirect_depth_summary.tsv", "ZB_redo", "Indirect"))

write_csv(Summary_Data, 'data/Summary_Data.csv')
```

```{r,warning=F,message=F,include=F,}
Summary_Data <- read_csv('data/Summary_Data.csv') 
```

```{r,warning=F,message=F,include=F}
## Summary table to be performed on collated data
Summary_Data %>% 
  group_by(Data, Alignment) %>% 
  summarise_all(mean) %>% 
  select(-ID, -Sample, -Genome)
```

\newpage

# Map Stats: number of reads mapping to reference genome

### Comparison across ZB dataset

Firstly, Field and I found an error in my trimming step on the ZB dataset that meant that I was working with truncated files. This resutled in running the ZB data through the workflow again. The plot below shows the difference it made on the number of reads mapping, with ZB_redo and ZB_bowtie using the 'corrected' dataset. Both outputs (ZB and ZB_redo) are included in some subsequent plots for more comparison.

```{r,warning=F,message=F,echo=F}
gridExtra::grid.arrange(
BBMAP %>% 
  filter(grepl("ZB", Data)) %>%
  filter(Alignment == "Direct") %>% 
  ggplot() + 
  geom_col(aes(x = ID, y = Mapped.reads/10000000, colour = Data)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = "Samples", y= "Mapped reads (M)") +
  facet_wrap(~Data) +
  ggtitle("Reads mapped when aligning directly to Pk."),

BBMAP %>% 
  filter(grepl("ZB", Data)) %>%
  filter(Alignment == "Indirect", Genome == "Pk") %>% 
  ggplot() + 
  geom_col(aes(x = ID, y = Mapped.reads/10000000, colour = Data)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = "Samples", y= "Mapped reads (M)") +
  facet_wrap(~Data) +
  ggtitle("Reads mapped with human contamination removed.")
)

```

## Comparison of the number reads mapping to Pk across all datasets and for different alignments

```{r,warning=F,message=F,echo=F}
BBMAP %>% 
  filter(Genome == "Pk") %>% 
  filter(Data != "ZB", Data != "ZB_bowtie") %>% 
  rbind(BBMAP %>% 
          filter(Data == "ZB_bowtie" & Genome =="Pk") %>% # wranlge the bowtie2 data so that it doesn't share names with other data - 'stacks' othersise
          select(-ID) %>% 
          add_column(ID = 1:13) %>% 
          mutate(ID = as.character(ID)) %>% 
          mutate(ID = as.factor(ID))) %>% 
  ggplot() + 
  geom_col(aes(x = ID, y = Mapped.reads/10000000, colour = Data)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = "Samples", y = "Mapped reads (M)") +
  facet_wrap(~Alignment) 
```

**Key points:**

 - ZB's data (ZB_redo) appears to get the most reads.
 - ZB's data is comparable to 'Previous Pk' data.
 - Mapping directly to Pk with bwa & indirectly via removal of the human genome with bowite2 is comparable.
 

## Plot a comparisons of mapped reads on ZB data for the indirect alignments with bowtie2 (for removing human contamination) and direct with bwa

```{r,warning=F,message=F,echo=F}
BBMAP %>% 
  filter(Data == "ZB_redo" & Alignment == "Direct") %>% 
  rbind(BBMAP %>% filter(Data == "ZB_bowtie" & Genome == "Pk")) %>% 
  ggplot() + 
  geom_col(aes(x = ID, y = Mapped.reads/10000000, colour = Data)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  labs(x = "Samples", y = "Mapped reads (M)") +
  facet_wrap(~Alignment)
```

### Calculate the average mapped reads for these two alignmetns

```{r,warning=F,message=F,echo=F}
BBMAP %>% 
  filter(Data == "ZB_redo" & Alignment == "Direct") %>% 
  rbind(BBMAP %>% 
          filter(Data == "ZB_bowtie" & Genome == "Pk")) %>%
  group_by(Data) %>% 
  summarise_all(mean) %>% 
  select(-ID, - Ref.scaffolds, -Ref.bases, -Alignment, -Genome, -Percent.mapped, -Percent.proper.pairs,
         -Standard.deviation, -Percent.scaffolds.with.any.coverage, -Percent.scaffolds.with.any.coverage) %>% 
  t() %>% 
  knitr::kable()
```

**Key points:**

 - Comparable, but mapping directly to Pk with bwa leads to more mapped reads and more coverage.

\newpage

# Read depth: number of reads aligning at each base

## Plot the average read depth per contig 

```{r,warning=F,message=F,echo=F}
Summary_Data %>% 
  group_by(Data, Alignment) %>% 
  summarise_all(mean) %>% 
  select(1:16) %>%  
  select(-3, -4) %>% 
  pivot_longer(cols = !c(Data, Alignment), names_to = "Contig", values_to = "Depth") %>% 
  ggplot() +
  geom_point(mapping = aes(x = Contig, y = Depth, colour = Data, shape = Alignment)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) 
```

## IGV

![Comparison of read depth across the genome for ZB_redo and Previous_Pk data (direct alignments)](C:/Users/Jacob/Desktop/Menzies/Knowlesi/Pipeline/Pk_Pipeline/data/IGV/igv_hist_ZBvsPREVIOUS.png)

Coloured by data:

 - Previous Pk data = light blue.
 - ZB data = dark blue.
 
![Comparison of read depth across the genome for ZB data](C:/Users/Jacob/Desktop/Menzies/Knowlesi/Pipeline/Pk_Pipeline/data/IGV/igv_hist_ZBvsBowtie2.png)

Coloured by alignment:

 - To Pk with bwa via removal of human contamination with bowtie2 = light blue.
 - Direct to Pk with BWA = red.
 - To Pk with bwa via removal of human contamination with bwa = dark blue.
 
## Plot the percentage of bases WITHOUT coverage
 
```{r,warning=F,message=F,echo=F}
Summary_Data %>% 
  group_by(Data, Alignment) %>% 
  summarise_all(mean) %>% 
  select(1:2, 19:32) %>% 
  pivot_longer(cols = !c(Data, Alignment), names_to = "Contig", values_to = "Bases") %>% 
  ggplot() +
  geom_point(mapping = aes(x = Contig, y = Bases, colour = Data, shape = Alignment)) +
  theme(axis.text.x = element_blank(), axis.ticks = element_blank()) +
  ylab("% of NA bases")
```

**Key points:**

 - Using ZB's data (ZB_redo) and aligning directly to the Pk genome produces the greatest read depth and is comparable to previous work (Previous_Pk) provided by Ernest.
 - Using ZB's data and aligning directly to the Pk genome also produces the lowest percentage of bases without coverage.
 - Despite being the best on average, IGV suggests there is inconsistency between samples within the ZB dataset.

# Explore the ZB data in more detail

## plott the read depth of each sample (direct alignment - ZB) at each contig

```{r,warning=F,message=F,echo=F}
Summary_Data %>% 
  filter(Alignment == "Direct", Data == "ZB_redo") %>% 
  select(1:18) %>%  
  pivot_longer(cols = !c(ID, Data, Alignment, Sample), names_to = "Contig", values_to = "Depth") %>% 
  ggplot(mapping = aes(x = Sample, y = Depth)) +
  geom_col() +
  facet_wrap(~Contig) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

**Key points:**

 - Despite a great average, the read depth per a sample is inconsistent.
 - The read depth across contigs within a sample is consistent.
 
## Read in metadata and combine with summary data to explore the effect of parasitemia alignment

```{r,warning=F,message=F,echo=F}
ZB_metadata <- Summary_Data %>% 
  filter(Data == "ZB_redo") %>% 
  mutate(ID = str_remove(ID, "_DKDL2.*")) %>%
  rename("sampleid" = ID) %>%  
  left_join(readxl::read_excel("data/metadata/PK_Sabah_Sample_naming_indexes.xlsx") %>% 
              select(sampleid, severe, parasitemia)) %>% 
  rename("ID" = sampleid)
```

## Explore the relationship between parasitemia read depth across samples

```{r,warning=F,message=F,echo=F}
ZB_metadata %>% 
  filter(Alignment == "Direct", Data == "ZB_redo") %>% 
  select(1:18, 47) %>%  
  pivot_longer(cols = !c(ID, Data, Alignment, Sample, parasitemia), names_to = "Contig", values_to = "Depth") %>% 
  ggplot(mapping = aes(x = Sample, y = Depth, fill = parasitemia/1000)) +
  geom_col() +
  facet_wrap(~Contig) +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank()) +
  scale_fill_continuous(name = "Parasitemia (k)")
```

## Plot relationship between depth across samples in relation to parasitemia, faceted by contig

```{r,warning=F,message=F,echo=F}
ZB_metadata %>% 
  filter(Alignment == "Direct", Data == "ZB_redo") %>% 
  select(1:18, 47) %>%  
  pivot_longer(cols = !c(ID, Data, Alignment, Sample, parasitemia), names_to = "Contig", values_to = "Depth") %>% 
  ggplot(mapping = aes(x = parasitemia/1000, y = Depth)) +
  geom_point() +
  geom_smooth(method = "lm", se = T) +
  facet_wrap(~Contig) +
  ylab("Depth") +
  xlab("Parasitemia (K)") +
  ggpubr::stat_regline_equation(label.y = 300, aes(label = ..rr.label..))
  
```

## Plot relationship between depth across samples in relation to parasitemia in the lower parasitemia samples, faceted by contig

```{r,warning=F,message=F,echo=F}
ZB_metadata %>% 
  filter(Alignment == "Direct", Data == "ZB_redo") %>% 
  select(1:18, 47) %>%  
  pivot_longer(cols = !c(ID, Data, Alignment, Sample, parasitemia), names_to = "Contig", values_to = "Depth") %>% 
  ggplot(mapping = aes(x = parasitemia/1000, y = Depth)) +
  geom_point() +
  geom_smooth(method = "lm", se = T) +
  facet_wrap(~Contig) +
  ylab("Depth") +
  xlab("Parasitemia (K)") +
  xlim(0, 100) +
  ggpubr::stat_regline_equation(label.y = 250, aes(label = ..rr.label..))
```

**Key points:**

 - There may be a **slight** relationship between paraistemia and read depth, that is stronger at the lower levels of parasitemia.
 
################################################################################################################################

# Exploring low parasitemia samples

Upon exploration of the mapping statistics and read depth for the ZB data, it was noted that none of the samples had parasitemia counts < 5000.
To determine if ZBs sequencing workflow is good enough for low parasitemia I ran an additional 16 samples through the pipeline.
I used the metadata to get the sample IDs, and then had to search for the files across the zipepd batches:

unzip -l batch2.zip | grep 'SB_DNA_060/|SB_DNA_072/|SB_DNA_059/|SB_DNA_062/|SB_DNA_083/|SB_DNA_069/|SB_DNA_068/|SBH_DNA_005/|SB_DNA_071/|SB_DNA_086/|SB_DNA_007/|SB_DNA_002'

unzip -j "batch2.zip" "batch2/PK_SB_DNA_075/PK_SB_DNA_075*" -d "/home/jwestaway/pk_pipeline/low_parasitemia/pk_data"

Then the following was performed similar scripts outlined above (same 'versions' etc.):

QC/MultiQC > Trimming > QC/MultiQC > Pk alignment > Map stats > Read depth 

The mapstats and read depth data was then read into R for analyis.


################################################################################################################################

# Bam Preprocessing

# First need to create a consensus VCF

A VCF with known variants is needed for bam preprocessing (indel realignment and base recalibration). 
As a consensus VCF has not be built, we must build our own. Here we use a combination of previously studies samples of known high quality (just below), and our own high quality samples to build a consensus VCF.
This follows a similar workflow to the standard calling of variants, where we mark duplicates, but we then skip realignment and recalibration, going straight to haplotype calling. 
We then combine the resulting VCF files to come up with a consensus.

## Process previously studied high quality samples

Samples: ERR274221, ERR274222, ERR274224, ERR274225, SRR2221468, SRR2222335, SRR2225467, SRR2225571, SRR2225573, SRR3135172
From https://www.pnas.org/content/112/42/13027.full & https://static-content.springer.com/esm/art%3A10.1038%2Fs41598-019-46398-z/MediaObjects/41598_2019_46398_MOESM1_ESM.pdf

File = 01_QC.pbs 
Version(s) = 0.10.1 (FastQC) & 0.1.9 (MultiQC)

```{R,eval=F}
#!/bin/bash
#PBS -N QC
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Export path to fastqc"
export PATH=$PATH:/usr/local/FastQC
export PATH=$PATH:/usr/local/singularity/latest/bin

echo "---------------------------------------"
echo "Change to current working directory"
cd pk_pipeline

echo "---------------------------------------"
echo "Set environment variable"
cd /home/jwestaway/pk_pipeline/vcf_data/pk_data/
OUTDIR="/home/jwestaway/pk_pipeline/vcf_data/pk_data/qc"
mkdir $OUTDIR

echo "---------------------------------------"
echo "Execute fastqc"
fastqc -t 10 -o $OUTDIR *.fastq.gz

echo "---------------------------------------"
echo "Change to output directory"
cd $OUTDIR

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec /home/jwestaway/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .

echo "---------------------------------------"
echo "Finsihed!"
```

File = Template.pbs
Version(s) = 3.1.0 (singularity), 0.6.4 (trim-galore), 20171222 (parallel), 1.12 (samtools) & 0.7.10 (bwa)

This job was submitted as a batch job, the scripts for which are located in vcf_data/scripts/02_Trim_align.

```{R,eval=F}
#!/bin/bash
#PBS -N Trim_&_Align
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=20gb
#PBS -l walltime=72:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "TRIMMING"

echo "---------------------------------------"
echo "Export paths and load modules"
export PATH=$PATH:/usr/local/singularity/latest/bin
export PATH=$PATH:/usr/local/parallel_20171222/bin

echo "---------------------------------------"
echo 'Change to current working directory' 
cd pk_pipeline

echo "---------------------------------------"
echo 'Set environment vars'
INPUTDIR="/home/jwestaway/pk_pipeline/vcf_data/pk_data/"
OUTDIR="/home/jwestaway/pk_pipeline/vcf_data/outputs/trimmed"

echo "---------------------------------------"
echo 'Exectue trim_galore for quality and adapter trimming'
parallel -j10 --xapply singularity exec ~/pk_pipeline/tools/singularity/trim-galore_0.6.4.sif trim_galore --illumina --paired --fastqc -o $OUTDIR ::: $INPUTDIR/SAMPLE_1.fastq.gz ::: $INPUTDIR/SAMPLE_2.fastq.gz

echo "---------------------------------------"
echo "ALIGNMENT"

echo "---------------------------------------"
echo "Define paths to bwa and samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/
export PATH=$PATH:/usr/local/bwa-0.7.10 

echo "---------------------------------------"
echo 'Change to working directory' 
cd /home/jwestaway/pk_pipeline/vcf_data/outputs/trimmed

echo "---------------------------------------"
echo 'Set environment vars'
OUTDIR="/home/jwestaway/pk_pipeline/vcf_data/outputs/pk_alignment/"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

echo "---------------------------------------"
echo 'Exectue alignment with bwa to hg and sort to bam'

bwa mem -t 10 -M -R "@RG\tID:SAMPLE\tPL:ILLUMINA" $INDEXTDIR SAMPLE_1_val_1.fq.gz SAMPLE_2_val_2.fq.gz | samtools view -u -S - | samtools sort -n -o $OUTDIR/SAMPLE.bam

echo "---------------------------------------"
echo "Finsihed!"
```

File = 03_Stats.pbs
Versions = 0.1.9 (MultiQC), 1.12 (samtools), 1.8.0_171 (Java), 0.6.3 (sambamba) & 38.90 (BBMap)

```{R,eval=F}
#!/bin/bash
#PBS -N Map_Stats
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=72:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"



echo "---------------------------------------"
echo 'MultiQC'

echo "---------------------------------------"
echo 'Change to working directory'
export PATH=$PATH:/usr/local/singularity/latest/bin
cd /home/jwestaway/pk_pipeline/vcf_data/outputs/trimmed

echo "---------------------------------------"
echo "Execute multiqc using singularity"
singularity exec /home/jwestaway/pk_pipeline/tools/singularity/multiqc_v0.1.9.sif multiqc .



echo "---------------------------------------"
echo 'BBMAP'

echo "---------------------------------------"
echo "Define paths to bbmap and samtools"
export Path=$PATH:/home/jwestaway/pk_pipeline/tools/bbmap
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/  
export PATH=$PATH:/usr/local/miniconda3/pkgs/quast-5.0.2-py37pl526hb5aa323_2/lib/python3.7/site-packages/quast_libs/sambamba
module load java/1.8.0_171

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/vcf_data/outputs/pk_alignment/
PILEUP="/home/jwestaway/pk_pipeline/tools/bbmap/pileup.sh"

echo "---------------------------------------"
echo 'Exectue samtools & bbmap'
for i in *.bam
do
samtools view -h --threads 20 $i | $PILEUP in=stdin 2> ${i%.bam}.mapstats
done 

echo "---------------------------------------"
echo 'Collate map stats data into a single csv'
tail -n +1 *mapstats | grep '.mapstats\|Read\|Mapped\|Ref\|Percent\|Average\|Standard' | sed 's/:/,/' | sed 's/<==/,/' > high_qual_mapstats.csv



echo "---------------------------------------"
echo 'READ DEPTH'

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'Set env variables'
BED='/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed'

echo "---------------------------------------"
echo 'Sort bam files'

for i in *.bam
do
samtools sort -@ 20 $i > ${i%.bam}.sorted.bam
done 

echo "---------------------------------------"
echo 'Index bam files'

for i in *.sorted.bam
do
samtools index -@ 20 $i 
done 

echo "---------------------------------------"
echo 'Create file with list of filenames'
ls *sorted.bam > filenames.txt

echo "---------------------------------------"
echo 'Exectue samtools depth'
samtools depth -a -b $BED -f filenames.txt -o high_qual_depth_summary.depth


echo "---------------------------------------"
echo "Finsihed!"
```


## Build consensus VCF

This step requires the production and then merging of GVCF files. We used two variant callers, GATK and samtools, and both our own data and some previously analysed high quality data:
 - Five lines maintained in laboratory rhesus macaques after isolation in the 1960s from Peninsular Malaysia and the Philippines - https://www.pnas.org/content/112/42/13027.full
 - Archived clinical isolates, prepared with a method to reduce the amount of human DNA in the thawed blood samples in preparation for high throughput parasite genome sequencing using Illumina HiSeq and MiSeq sequencing platforms - https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0121303

GATK requires that the reference genome has .dict and .fai files:
'/usr/local/jdk1.8.0_131/bin/java -jar /usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar CreateSequenceDictionary R=strain_A1_H.1.Icor.fasta'
'samtools faidx strain_A1_H.1.Icor.fasta'

### Bam Preprocessing

Duplicate were 'marked' and the header line had to be changed, as GATK is specific about what it requires for @RG.
These jobs were run per sample. Look at previous examples above on how batch jobs were created.

Versions: 1.12 (samtools), 1.8.0_131 (Java), 2.21.9 (picard)
File: bam_preprocessing.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Bam_pre
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/jdk1.8.0_131/bin
export PATH=$PATH:/usr/local/jre1.8.0_111/bin
export PATH=$PATH:/usr/local/GenomeAnalysisTK-3.2.2 
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
INDIR="/home/jwestaway/pk_pipeline/vcf_data/outputs/pk_alignment"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/SAMPLE"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

mkdir $OUTDIR

echo "---------------------------------------"
echo 'MarkDuplicates'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -jar $PICARD \
    MarkDuplicates AS=TRUE VALIDATION_STRINGENCY=LENIENT \
    I=$INDIR/SAMPLE.sorted.bam \
    O=$OUTDIR/SAMPLE.dupmarked.bam \
    M=$OUTDIR/SAMPLE_picard_metrics_file.txt 

echo "---------------------------------------"
echo 'Change header @RG and index' 
samtools view -H $OUTDIR/SAMPLE.dupmarked.bam | \
    sed 's,^@RG.*,@RG\tID:SAMPLE\tSM:SAMPLE\tLB:None\tPL:Illumina,g' |  \
    samtools reheader - $OUTDIR/SAMPLE.dupmarked.bam > $OUTDIR/SAMPLE.dupmarked.reheader.bam

samtools index $OUTDIR/SAMPLE.dupmarked.reheader.bam 

echo "---------------------------------------"
echo 'Finished' 
```

### GATK 

#### HaplotypeCaller

Versions: 1.8.0_131 (Java), 2.21.9 (picard), 3.2.2 (GATK)
File: Template.pbs

A seperate job was run for each sample.

HaplotypeCaller Arguments:
 - nt - number of threads
 - ERC - mode for emitting reference confidence scores
 - minPruning - the number of samples that must pass the pruning threshold
 - maxNumHaplotypesInPopulation - each haplotype considered requires n evaluations if there are n reads across all samples, so this argument defines a specific number to control this. Dropping this too low can result in missing variants.
 - max_alternate_alleles - maximum number of alternate alleles to genotype
 - contamination - fraction of contamination in sequencing data to aggresively remove. If > 0, the caller will remove contamination through biased down sampling of the reads
 - variant_index_type LINEAR & variant_index_parameter 128000 - old dodgey workaround that GATK used for index compression. Newer versions no longer need this 

```{R,eval=F}
#!/bin/bash
#PBS -N Haplotype
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/jdk1.8.0_131/bin
export PATH=$PATH:/usr/local/jre1.8.0_111/bin
export PATH=$PATH:/usr/local/GenomeAnalysisTK-3.2.2 

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/SAMPLE
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

echo "---------------------------------------"
echo 'HaplotypeCaller' 

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T HaplotypeCaller \
    -nt 1 \
    -ERC GVCF \
    --minPruning 3 \
    --maxNumHaplotypesInPopulation 200 \
    --max_alternate_alleles 3 \
    --variant_index_type LINEAR \
    --variant_index_parameter 128000 \
    -contamination 0.0 \
    -G Standard \
    -R $INDEXTDIR \
    -I SAMPLE.dupmarked.reheader.bam \
    -o SAMPLE.haplotypecaller.g.vcf.gz

echo "---------------------------------------"
echo 'Finished' 
```

After running HaplotypeCaller, we need to move all these files to the same location to then execute CombineGVCFs, and then GenotypeCaller

`mkdir /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs`

`mv /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/*/*.haplotypecaller.g.vcf.gz /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs`
`mv /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/*/*.haplotypecaller.g.vcf.gz.tbi /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs`

#### CombineGVCFs and GenotypeCaller

Versions: 1.8.0_131 (Java), 2.21.9 (picard), 3.2.2 (GATK)
File: joint_genotype.pbs

Arguments:
 - G - annotations

```{R,eval=F}
#!/bin/bash
#PBS -N GATK_genotype
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=200gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/jdk1.8.0_131/bin
export PATH=$PATH:/usr/local/jre1.8.0_111/bin
export PATH=$PATH:/usr/local/GenomeAnalysisTK-3.2.2 
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo 'Set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs

echo "---------------------------------------"
echo 'CombineGVCFs'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T CombineGVCFs \
    -R $INDEXTDIR \
    -V ERR274221.haplotypecaller.g.vcf.gz -V ERR274222.haplotypecaller.g.vcf.gz -V ERR274224.haplotypecaller.g.vcf.gz -V ERR274225.haplotypecaller.g.vcf.gz -V PK_SB_DNA_006_DKDL210002135-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_008_DKDL210002137-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_009_DKDL210002138-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_011_DKDL210002140-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_012_DKDL210002141-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_014_DKDL210002143-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_015_DKDL210002144-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_019_DKDL210002148-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_023_DKDL210002152-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_030_DKDL210002159-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_031_DKDL210002160-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_033_DKDL210002162-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_034_DKDL210002163-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_057_DKDL210002186-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_058_DKDL210002187-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_061_DKDL210002190-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_063_DKDL210002192-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_064_DKDL210002193-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_065_DKDL210002194-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_066_DKDL210002195-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_070_DKDL210002199-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_073_DKDL210002202-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_074_DKDL210002203-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_075_DKDL210002204-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_076_DKDL210002205-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_080_DKDL210002209-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_092_DKDL210002221-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_093_DKDL210002222-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V PK_SB_DNA_094_DKDL210002223-1a_HWHGKDSXY_L4.haplotypecaller.g.vcf.gz -V SRR2221468.haplotypecaller.g.vcf.gz -V SRR2222335.haplotypecaller.g.vcf.gz -V SRR2225467.haplotypecaller.g.vcf.gz -V SRR2225571.haplotypecaller.g.vcf.gz -V SRR2225573.haplotypecaller.g.vcf.gz -V SRR3135172.haplotypecaller.g.vcf.gz \
    -o Combined.g.vcf.gz

echo "---------------------------------------"
echo 'GenotypeGVCFs' 

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T GenotypeGVCFs \
    -nt 20 \
    -R $INDEXTDIR \
    -V Combined.g.vcf.gz \
    -o $OUTDIR/Genotyped.vcf.gz

echo "---------------------------------------"
echo 'Finished' 
```

### bcftools

The pre-calling steps were carried out above with GATK, and so the *.dupmarked.reheader.bam files can be passed directly into bcftools.

mpileup part generates genotype likelihoods at each genomic position with coverage. The second call part makes the actual calls. 

Before running script:

mkdir cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams
mv /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/*/*.dupmarked.reheader.bam /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams

ls /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams/*.dupmarked.reheader.bam \
    | tr '\n' '\0' | xargs -0 -n 1 basename \
    > input_bam_files.list

Versions: 1.13 (bcftools)
File: bcftools_variants_only.pbs (in /variants_only_test)

**NB** The variants_only_test was a directory that was used to test for selecting only variants from with the bcftools caller. 
As this turned out to be the correct method, many of the subsequent files are redirected through this directory, and the correseponding output directory.

Arguments:
 - m - Alternative model for multiallelic and rare-variant calling
 - Oz - compressed output
 - a - annotate with the following parameters
 - v - variants only  

```{R,eval=F}
#!/bin/bash
#PBS -N bcftools_variants_only
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=200gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/bcftools-1.13/

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/"

echo "---------------------------------------"
echo 'Call variants with samtools'

bcftools mpileup --threads 20 -f $INDEXTDIR -b input_bam_files.list \
   | bcftools call -m -Oz -a FORMAT/GQ,FORMAT/GP,INFO/PV4 -v -o $OUTDIR/PK_samtools_variants_only_header.raw.vcf.gz

bcftools index --threads 20 -t -o $OUTDIR/PK_samtools_variants_only_header.raw.vcf.gz.tbi $OUTDIR/PK_samtools_variants_only_header.raw.vcf.gz

echo "---------------------------------------"
echo "Finsihed!"
```

### Merge variants from the two variant callers

Versions: 1.13 (bcftools)
File: samtools_merge_vcfs.pbs (in /variants_only_test)

Arguments:
 - force-samples - the same samples were called on both variant callers and so the names in the two vcf files are the same. This argument will assign a prefix of '2:' to the names from the second VCF file, so that we can differentiate between the two.

```{R,eval=F}
#!/bin/bash
#PBS -N merge_vcfs
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=100gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/bcftools-1.13/

echo "---------------------------------------"
echo 'Change to working directory and set env variables'
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/

echo "---------------------------------------"
echo 'Execute bcftools merge'
bcftools merge --threads 15 --force-samples -o merged_variants_only.vcf.gz GATK/Genotyped.vcf.gz samtools/PK_samtools_variants_only_header.raw.vcf.gz

echo "---------------------------------------"
echo 'Finished' 
```
 
### Create Consensus VCF

Versions: 1.13 (bcftools), 3.6.2 (R)
File: Consensus_variants.pbs

This script filters the merged VCF file for variants the fulfil the defined criteria, and outputs these variants and the samples they were observed in, along with several variant metrics, to a TSV file.

The script queries the two tool-specific VCF files to get a list of the variants found in both.
An R script is then used to select variants found by both tools (consesnus/overlap).
This list of consensus variants is then used to select (fgrep) the 'consensus variants' from the merged VCF file (above), creating a Consensus VCF.
The default language was changed to ASCII (fewer characters than UTF8) and fgrep used to speed up the grep process. The language change reduces the number of possible characters from ~11,000 to 123, and fgrep searchs for matches of the entire string pattern instead of by characrter within the string.

Arguments:
  - bcftools query
    - f - format - inside the square brackets are for the annotation-specific column, whereas the annotations outside have their own column
  - fgrep 
    - f - file of patterns to search for

```{R,eval=F}
#!/bin/bash
#PBS -N Consensus_var
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=30
#PBS -l mem=300gb
#PBS -l pmem=300gb
#PBS -l file=200gb
#PBS -l walltime=8:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to bcftools and miniconda, load the R module, change to working directory and create an output directory"
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/bcftools-1.13/
module load software/R_3.6.2
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/

echo "---------------------------------------"
echo "Exectute bcftools to select variants that pass a specific threshold"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/Genotyped.vcf.gz > GATK_query.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/PK_samtools_variants_only_header.raw.vcf.gz > samtools_query.tsv

echo "---------------------------------------"
echo "Execute R script to get consensus variants and stats"
source /usr/local/miniconda3/etc/profile.d/conda.sh
conda activate R_3.6.2
Rscript /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/vcf_wrangle_2.R
conda deactivate

echo "---------------------------------------"
echo "Use vcf_variant_names to filter the original merged vcf for variants called by both tools"

echo "---------------------------------------"
echo "Create a seperate file that contains all the header information for the vcf"
zcat merged_variants_only.vcf.gz | head -n 85 > vcf_head.vcf 

echo "---------------------------------------"
echo "Remove the column names from the variant names document to create a list of grep patterns"
tail -n +2 vcf_variant_names.tsv > grep_patterns.txt 

echo "---------------------------------------"
echo "Change default language to ASCII - fewer characters than UTF8"
LC_ALL=C

echo "---------------------------------------"
echo "Filter for variants from the original vcf that are called by both callers by using grep to match patterns created above" 
bcftools view merged_variants_only.vcf.gz | fgrep -f grep_patterns.txt - > filtered.vcf

echo "---------------------------------------"
echo "Concatenate the vcf header in the variants called by both callers"
cat vcf_head.vcf filtered.vcf > PK_consensus.vcf

echo "---------------------------------------"
echo "Finished "
```


#### Wrangling R script

File = vcf_wrangle_2.R

```{R,eval=F}
# Load Packages
library(dplyr)
library(tidyr)
library(readr)
library(tibble)
library(stringr)
library(forcats)

Names <- c("X1") # X1 is the first columns
for (i in 1:100){
  Names <- append(Names, print(paste0("Sample_", i)))
}

read_tsv("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GATK_query.tsv", col_names =  Names) %>% 
  select(X1) %>% 
  inner_join(read_tsv("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/samtools_query.tsv", col_names =  Names) %>% 
               select(X1)) %>% 
  separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt")) %>% 
  write_tsv("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/variants_only_test/vcf_variant_names2.tsv")
```


###########################################################################################################################################################


# Filtering Variants 

Testing different filtering paramaters against our consensus VCF to determine what will be best for our data. 
These filters can be used to improve our truth/consensus set and downstream when calling variants during our actual analysis.
Need to determine the filtering parameters for variant calling that we should use. 
In addition, we need to apply filtering to our truth set to produce the most "real" datset possible, so that indel realignment and the training of models for VQSR are accurate.


## Create VCFs for SNPs/Indels only from the PK Consensus

Required for variant-specific filtering.

Versions: 
File: snps_and_indels.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Calc_snps_&_indels
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=12:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths and change to working directory"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/

echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V PK_consensus.vcf \
    --select-type-to-include SNP \
    -O GVCFall_SNPs.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V PK_consensus.vcf \
    --select-type-to-include INDEL \
    -O GVCFall_INDELs.vcf

echo "---------------------------------------"
echo "Finsihed"
```


## Create VCFs for SNPs/Indels only for tool-specific VCF files

We create these tool-specific SNP and Indels VCF files so that we can see how the different filters effect the different tools, and not just the consensus. 
This can give us an idea of the quality of the two variant callers, and how their quality may effect the final consenus post-filtering, as poor variant quality in one tool may bring down the average of the two tools and result in a greater loss of variants.

Versions: 
File: snps_and_indels.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Calc_snps_&_indels
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=12:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths and change to working directory"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus


echo "---------------------------------------"
echo "GATK"


echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V GATK/Genotyped.vcf.gz \
    --select-type-to-include SNP \
    -O GATK/GVCFall_SNPs_GATK.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V GATK/Genotyped.vcf.gz \
    --select-type-to-include INDEL \
    -O GATK/GVCFall_INDELs_GATK.vcf


echo "---------------------------------------"
echo "samtools/bcftools"


echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V samtools/PK_samtools_variants_only_header.raw.vcf.gz \
    --select-type-to-include SNP \
    -O samtools/GVCFall_SNPs_bcftools.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V samtools/PK_samtools_variants_only_header.raw.vcf.gz \
    --select-type-to-include INDEL \
    -O samtools/GVCFall_INDELs_bcftools.vcf

echo "---------------------------------------"
echo "Finsihed"
```


## Filtering tests 

### Original Dataset

This is just to calculate the SNPs and Indels in the original data for comparisons sake.

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard)
File: original/variant_filtering.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Filter_variants_original
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir $OUTDIR
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V GVCFall_SNPs.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V GVCFall_INDELs.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs.table


echo "---------------------------------------"
echo 'Query data for comparison'
echo "---------------------------------------"

echo "---------------------------------------"
echo "SNPs"

echo "---------------------------------------"
echo "Exectute bcftools to select variants that pass a specific threshold: FMT/GQ>30 & FMT/DP>10"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' variants_only_test/GVCFall_SNPs.vcf > $OUTDIR/SNPs.tsv

echo "---------------------------------------"
echo "Indels"

echo "---------------------------------------"
echo "Exectute bcftools to select variants that pass a specific threshold: FMT/GQ>30 & FMT/DP>10"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' variants_only_test/GVCFall_INDELs.vcf > $OUTDIR/indels.tsv



echo "---------------------------------------"
echo "query tool-specific data"
echo "---------------------------------------"



echo "---------------------------------------"
echo 'GATK'

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs_GATK.table

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs_GATK.table

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' GATK/GVCFall_SNPs_GATK.vcf > $OUTDIR/SNPs_GATK.tsv

echo "---------------------------------------"
echo "Indels"

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' GATK/GVCFall_INDELs_GATK.vcf > $OUTDIR/indels_GATK.tsv



echo "---------------------------------------"
echo 'samtools'

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs_bcftools.table

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs_bcftools.table

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' samtools/GVCFall_SNPs_bcftools.vcf > $OUTDIR/SNPs_bcftools.tsv

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' samtools/GVCFall_INDELs_bcftools.vcf > $OUTDIR/indels_bcftools.tsv

echo "---------------------------------------"
echo 'Finished'
```

### GATK Best Practices Filter

These filtering parameters are based on GATK best practices.

https://gatk.broadinstitute.org/hc/en-us/articles/360035531112--How-to-Filter-variants-either-with-VQSR-or-by-hard-filtering

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard)
File: GATK_BP/variant_filtering.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Filter_variants_GATK_BP
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir $OUTDIR
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus


echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered.vcf


echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered.vcf


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/snps_filtered.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/indels_filtered.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs.table


echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

echo "---------------------------------------"
echo "SNPs"

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs.tsv

echo "---------------------------------------"
echo "Indels"

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels.tsv



echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"
echo "---------------------------------------"



echo "---------------------------------------"
echo 'GATK'

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_GATK.vcf


echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_GATK.vcf


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/snps_filtered_GATK.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs_GATK.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/indels_filtered_GATK.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs_GATK.table

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK.tsv

echo "---------------------------------------"
echo "Indels"

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK.tsv



echo "---------------------------------------"
echo 'samtools'

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_bcftools.vcf


echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_bcftools.vcf


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/snps_filtered_bcftools.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs_bcftools.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/indels_filtered_bcftools.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs_bcftools.table

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools.tsv

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools.tsv


echo "---------------------------------------"
echo 'Finished'
```

### Vivax Filter 

These filtering parameters are those appalied to *P. vivax* by the Sanger Institute.

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard)
File: Vivax/variant_filtering.pbs 

```{R,eval=F}
#!/bin/bash
#PBS -N Filter_variants_vivax
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered.vcf


echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered.vcf


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/snps_filtered.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/indels_filtered.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs.table


echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

echo "---------------------------------------"
echo "SNPs"

echo "---------------------------------------"
echo "Exectute bcftools to select variants that pass a specific threshold: FMT/GQ>30 & FMT/DP>10"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs.tsv

echo "---------------------------------------"
echo "Indels"

echo "---------------------------------------"
echo "Exectute bcftools to select variants that pass a specific threshold: FMT/GQ>30 & FMT/DP>10"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels.tsv






echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"
echo "---------------------------------------"




echo "---------------------------------------"
echo 'GATK'


echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_GATK.vcf


echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_GATK.vcf

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/snps_filtered_GATK.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs_GATK.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/indels_filtered_GATK.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs_GATK.table

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK.tsv

echo "---------------------------------------"
echo "Indels"

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK.tsv



echo "---------------------------------------"
echo 'samtools'

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_bcftools.vcf


echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - snps'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/snps_filtered_bcftools.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_SNPs_bcftools.table


echo "---------------------------------------"
echo 'Make diagnostic tables for Variants Scores - indels'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantsToTable \
    -R $INDEXTDIR \
    -V $OUTDIR/indels_filtered_bcftools.vcf \
    -F CHROM -F POS -F QUAL -F QD -F DP -F MQ -F GQ -F MQRankSum -F FS -F ReadPosRankSum -F SOR \
    -O $OUTDIR/GVCFall_INDELs_bcftools.table

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools.tsv


echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools.tsv

echo "---------------------------------------"
echo 'Finished'
```

### Creating a summary

Versions: 3.6.2 (R)
File: filter_summary.pbs


```{R,eval=F}
#!/bin/bash
#PBS -N Filter_summary
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=30
#PBS -l mem=150gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Load the R module"
module load software/R_3.6.2

echo "---------------------------------------"
echo "Execute R script to get summary of different filters"
source /usr/local/miniconda3/etc/profile.d/conda.sh
conda activate R_3.6.2
Rscript /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/filtering_test/filter_comparison.R
conda deactivate

echo "---------------------------------------"
echo "Finished"
```

#### R script nested in the PBS script above

File = filter_comparison.R

```{R,eval=F}
# Load Packages
library(dplyr)
library(tidyr)
library(readr)
library(tibble)
library(stringr)
library(forcats)

#########################################################################################################################################################

# Define function for variant totals

variant_count_total <- function(INDEL_TSV, SNP_TSV, FILTER){

Names <- c("X1") # X1 is the first columns
for (i in 1:100){
  Names <- append(Names, print(paste0("Sample_", i)))
}
# Need to create names for the columns as the first row only has 7 columns, and thus R assumes all rows only have 7 columns and we end up losing a significant amount of data
Variants <- read_tsv(INDEL_TSV, col_names =  Names) %>% 
  separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt")) %>%  
  pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
  select(-name) %>% 
  na.omit() %>% 
  mutate(V_Call_Tool = ifelse(grepl("2:", value), "BCFTOOLS", "GATK")) %>% 
  separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
  mutate(DP = str_remove(DP, "DP=")) %>% 
  mutate(GQ = str_remove(GQ, "GQ=")) %>% 
  mutate(MQ = str_remove(MQ, "MQ=")) %>% 
  mutate(PL = str_remove(PL, "PL=")) %>% 
  mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
  add_column(Variant = "Indel") %>% 
  rbind(
   read_tsv(SNP_TSV, col_names =  Names) %>% 
     separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt")) %>% 
     pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
     select(-name) %>% 
     na.omit() %>% 
     mutate(V_Call_Tool = ifelse(grepl("2:", value), "BCFTOOLS", "GATK")) %>% 
     separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
     mutate(DP = str_remove(DP, "DP=")) %>% 
     mutate(GQ = str_remove(GQ, "GQ=")) %>% 
     mutate(MQ = str_remove(MQ, "MQ=")) %>% 
     mutate(PL = str_remove(PL, "PL=")) %>% 
     mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
     add_column(Variant = "SNP")  
   ) %>% 
  separate(Alt, c("ALT1", "ALT2", "ALT3", "ALT4", "ALT5", "ALT6"), sep = ",") %>% 
  pivot_longer(5:10, names_to = "ALT_N", values_to = "Alt") %>% 
  select(-ALT_N) %>% 
  na.omit(Alt)

Variants_2 <- Variants %>% # up to here produces a df that lists every variant-sample combination & below summarises this to give us counts
  unite(Variant_ID, Contig, Base, ID, Ref, Alt, sep = "-") %>% 
  mutate_if(is.character, as.factor) %>% 
  group_by(Variant) %>% 
  dplyr::summarise(Variant_Count = length(unique(Variant_ID)), 
                   GQ = mean(GQ),
                   DP = mean(DP),
                   MQ = mean(MQ)) 

Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
  select(-c(GQ, DP, MQ)) %>% 
  pivot_wider(c(Filter, Variant_Count), names_from = Variant, values_from = Variant_Count) %>% 
  left_join(
    Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
    select(Filter, GQ, DP, MQ) %>% 
    group_by(Filter) %>% 
    summarise_all(mean)) %>% 
  mutate(Total = Indel + SNP) %>% 
  relocate(Filter, Total, SNP, Indel)
}

#########################################################################################################################################################

# Define function for tool-specific counts

variant_count_tool_spec <- function(INDEL_TSV, SNP_TSV, FILTER, TOOL){

Names <- c("X1") # X1 is the first columns
for (i in 1:100){
  Names <- append(Names, print(paste0("Sample_", i)))
}
# Need to create names for the columns as the first row only has 7 columns, and thus R assumes all rows only have 7 columns and we end up losing a significant amount of data
Variants <- read_tsv(INDEL_TSV, col_names =  Names) %>% 
  separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt")) %>% 
  pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
  select(-name) %>% 
  na.omit() %>% 
  separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
  mutate(DP = str_remove(DP, "DP=")) %>% 
  mutate(GQ = str_remove(GQ, "GQ=")) %>% 
  mutate(MQ = str_remove(MQ, "MQ=")) %>% 
  mutate(PL = str_remove(PL, "PL=")) %>% 
  mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
  add_column(Variant = "Indel") %>% 
  rbind(
   read_tsv(SNP_TSV, col_names =  Names) %>% 
     separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt"))  %>% 
     pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
     select(-name) %>% 
     na.omit() %>% 
     separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
     mutate(DP = str_remove(DP, "DP=")) %>% 
     mutate(GQ = str_remove(GQ, "GQ=")) %>% 
     mutate(MQ = str_remove(MQ, "MQ=")) %>% 
     mutate(PL = str_remove(PL, "PL=")) %>% 
     mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
     add_column(Variant = "SNP")  
   ) %>% 
  separate(Alt, c("ALT1", "ALT2", "ALT3", "ALT4", "ALT5", "ALT6"), sep = ",") %>% 
  pivot_longer(5:10, names_to = "ALT_N", values_to = "Alt") %>% 
  select(-ALT_N) %>% 
  na.omit(Alt)

Variants_2 <- Variants %>% # up to here produces a df that lists every variant-sample combination & below summarises this to give us counts
  unite(Variant_ID, Contig, Base, ID, Ref, Alt, sep = "-") %>% 
  mutate_if(is.character, as.factor) %>% 
  group_by(Variant) %>% 
  dplyr::summarise(Variant_Count = length(unique(Variant_ID)), 
                   GQ = mean(GQ),
                   DP = mean(DP),
                   MQ = mean(MQ)) 

Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
  select(-c(GQ, DP, MQ)) %>% 
  pivot_wider(c(Filter, Variant_Count), names_from = Variant, values_from = Variant_Count) %>% 
  left_join(
    Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
    select(Filter, GQ, DP, MQ) %>% 
    group_by(Filter) %>% 
    summarise_all(mean)) %>% 
  mutate(Total = Indel + SNP) %>% 
  relocate(Filter, Total, SNP, Indel)  %>% 
  rename_at(vars(SNP), funs(paste0(TOOL, "_SNP"))) %>% 
  rename_at(vars(Indel), funs(paste0(TOOL, "_Indel"))) %>% 
  select(1,3:4)

}

#########################################################################################################################################################

# Use functions with left_join to combine 'orgiginal data'

# ORIGINAL
ORIGINAL <- variant_count_total("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original/indels.tsv", 
                    "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original/SNPs.tsv", 
                    "ORIGINAL") %>% 
  left_join(variant_count_tool_spec("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original/indels_GATK.tsv", 
                        "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original/SNPs_GATK.tsv", 
                        "ORIGINAL", "GATK")) %>% 
  left_join(variant_count_tool_spec("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original/indels_bcftools.tsv", 
                        "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/original/SNPs_bcftools.tsv", 
                        "ORIGINAL", "bcftools")) 


#########################################################################################################################################################

# Alter Functions for filters

#########################################################################################################################################################

# Define function for variant totals

variant_count_total <- function(INDEL_TSV, SNP_TSV, FILTER){

Names <- c("X1") # X1 is the first columns
for (i in 1:100){
  Names <- append(Names, print(paste0("Sample_", i)))
}
# Need to create names for the columns as the first row only has 7 columns, and thus R assumes all rows only have 7 columns and we end up losing a significant amount of data
Variants <- read_tsv(INDEL_TSV, col_names =  Names) %>% 
  separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt", "FILTER")) %>% 
  select(-FILTER) %>% 
  pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
  select(-name) %>% 
  na.omit() %>% 
  mutate(V_Call_Tool = ifelse(grepl("2:", value), "BCFTOOLS", "GATK")) %>% 
  separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
  mutate(DP = str_remove(DP, "DP=")) %>% 
  mutate(GQ = str_remove(GQ, "GQ=")) %>% 
  mutate(MQ = str_remove(MQ, "MQ=")) %>% 
  mutate(PL = str_remove(PL, "PL=")) %>% 
  mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
  add_column(Variant = "Indel") %>% 
  rbind(
   read_tsv(SNP_TSV, col_names =  Names) %>% 
     separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt", "FILTER")) %>% 
     select(-FILTER) %>% 
     pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
     select(-name) %>% 
     na.omit() %>% 
     mutate(V_Call_Tool = ifelse(grepl("2:", value), "BCFTOOLS", "GATK")) %>% 
     separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
     mutate(DP = str_remove(DP, "DP=")) %>% 
     mutate(GQ = str_remove(GQ, "GQ=")) %>% 
     mutate(MQ = str_remove(MQ, "MQ=")) %>% 
     mutate(PL = str_remove(PL, "PL=")) %>% 
     mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
     add_column(Variant = "SNP")  
   ) %>% 
  separate(Alt, c("ALT1", "ALT2", "ALT3", "ALT4", "ALT5", "ALT6"), sep = ",") %>% 
  pivot_longer(5:10, names_to = "ALT_N", values_to = "Alt") %>% 
  select(-ALT_N) %>% 
  na.omit(Alt)

Variants_2 <- Variants %>% # up to here produces a df that lists every variant-sample combination & below summarises this to give us counts
  unite(Variant_ID, Contig, Base, ID, Ref, Alt, sep = "-") %>% 
  mutate_if(is.character, as.factor) %>% 
  group_by(Variant) %>% 
  dplyr::summarise(Variant_Count = length(unique(Variant_ID)), 
                   GQ = mean(GQ),
                   DP = mean(DP),
                   MQ = mean(MQ)) 

Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
  select(-c(GQ, DP, MQ)) %>% 
  pivot_wider(c(Filter, Variant_Count), names_from = Variant, values_from = Variant_Count) %>% 
  left_join(
    Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
    select(Filter, GQ, DP, MQ) %>% 
    group_by(Filter) %>% 
    summarise_all(mean)) %>% 
  mutate(Total = Indel + SNP) %>% 
  relocate(Filter, Total, SNP, Indel)
}

#########################################################################################################################################################

# Define function for tool-specific counts

variant_count_tool_spec <- function(INDEL_TSV, SNP_TSV, FILTER, TOOL){

Names <- c("X1") # X1 is the first columns
for (i in 1:100){
  Names <- append(Names, print(paste0("Sample_", i)))
}
# Need to create names for the columns as the first row only has 7 columns, and thus R assumes all rows only have 7 columns and we end up losing a significant amount of data
Variants <- read_tsv(INDEL_TSV, col_names =  Names) %>% 
  separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt", "FILTER")) %>% 
  select(-FILTER) %>% 
  pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
  select(-name) %>% 
  na.omit() %>% 
  separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
  mutate(DP = str_remove(DP, "DP=")) %>% 
  mutate(GQ = str_remove(GQ, "GQ=")) %>% 
  mutate(MQ = str_remove(MQ, "MQ=")) %>% 
  mutate(PL = str_remove(PL, "PL=")) %>% 
  mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
  add_column(Variant = "Indel") %>% 
  rbind(
   read_tsv(SNP_TSV, col_names =  Names) %>% 
     separate(X1, sep =" ", c("Contig", "Base", "ID", "Ref", "Alt", "FILTER")) %>% 
     select(-FILTER) %>% 
     pivot_longer(cols = !c(Contig, Base, ID, Ref, Alt)) %>%  
     select(-name) %>% 
     na.omit() %>% 
     separate(value, sep = " ", c("Sample", "DP", "GQ", "MQ", "PL")) %>% 
     mutate(DP = str_remove(DP, "DP=")) %>% 
     mutate(GQ = str_remove(GQ, "GQ=")) %>% 
     mutate(MQ = str_remove(MQ, "MQ=")) %>% 
     mutate(PL = str_remove(PL, "PL=")) %>% 
     mutate_at(c("DP", "GQ", "MQ"), as.numeric) %>% 
     add_column(Variant = "SNP")  
   ) %>% 
  separate(Alt, c("ALT1", "ALT2", "ALT3", "ALT4", "ALT5", "ALT6"), sep = ",") %>% 
  pivot_longer(5:10, names_to = "ALT_N", values_to = "Alt") %>% 
  select(-ALT_N) %>% 
  na.omit(Alt)

Variants_2 <- Variants %>% # up to here produces a df that lists every variant-sample combination & below summarises this to give us counts
  unite(Variant_ID, Contig, Base, ID, Ref, Alt, sep = "-") %>% 
  mutate_if(is.character, as.factor) %>% 
  group_by(Variant) %>% 
  dplyr::summarise(Variant_Count = length(unique(Variant_ID)), 
                   GQ = mean(GQ),
                   DP = mean(DP),
                   MQ = mean(MQ)) 

Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
  select(-c(GQ, DP, MQ)) %>% 
  pivot_wider(c(Filter, Variant_Count), names_from = Variant, values_from = Variant_Count) %>% 
  left_join(
    Variants_2 %>% 
  add_column(Filter = FILTER) %>% 
    select(Filter, GQ, DP, MQ) %>% 
    group_by(Filter) %>% 
    summarise_all(mean)) %>% 
  mutate(Total = Indel + SNP) %>% 
  relocate(Filter, Total, SNP, Indel)  %>% 
  rename_at(vars(SNP), funs(paste0(TOOL, "_SNP"))) %>% 
  rename_at(vars(Indel), funs(paste0(TOOL, "_Indel"))) %>% 
  select(1,3:4)

}

#########################################################################################################################################################

# Use functions with left_join to combine filters

# GATK_BP
GATK_BP <- variant_count_total("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/indels.tsv", 
                    "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/SNPs.tsv", 
                    "GATK_BP") %>% 
  left_join(variant_count_tool_spec("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/indels_GATK.tsv", 
                        "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/SNPs_GATK.tsv", 
                        "GATK_BP", "GATK")) %>% 
  left_join(variant_count_tool_spec("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/indels_bcftools.tsv", 
                        "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/SNPs_bcftools.tsv", 
                        "GATK_BP", "bcftools")) 

# VIVAX
VIVAX <- variant_count_total("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/indels.tsv", 
                    "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/SNPs.tsv", 
                    "VIVAX") %>% 
  left_join(variant_count_tool_spec("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/indels_GATK.tsv", 
                        "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/SNPs_GATK.tsv", 
                        "VIVAX", "GATK")) %>% 
  left_join(variant_count_tool_spec("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/indels_bcftools.tsv", 
                        "/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/SNPs_bcftools.tsv", 
                        "VIVAX", "bcftools")) 

#########################################################################################################################################################

# Use rbind to create a summary files

ORIGINAL %>%
    rbind(GATK_BP) %>%
    rbind(VIVAX) %>%
    write_tsv("/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Filtering_Summary.tsv")

```


### Get counts for applying filters to consensus variants from the tools

Above we apply the filters to the 'raw' variant calls from the two variant calling tools. 
Here we select only the consensus variants from the tool-specific VCF, and pass these through the two filters. 
The first script selects the 'consensus variants' from the tool-specific outputs, and the second script applies the filters, outputing tsv files that can be interogated.

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard) & 1.13 (bcftools)
File: consensus_variants_from_tools.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Consensus_from_tools
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=30
#PBS -l mem=300gb
#PBS -l pmem=300gb
#PBS -l file=200gb
#PBS -l walltime=8:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths and set variables"
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/bcftools-1.13/
GATK="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/"
bcftools="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/variants_only_test/


echo "---------------------------------------"
echo "GATK"
echo "---------------------------------------"


echo "---------------------------------------"
echo "Use vcf_variant_names to filter the original merged vcf for variants called by both tools"

echo "---------------------------------------"
echo "Create a seperate file that contains all the header information for the vcf"
zcat $GATK/Genotyped.vcf.gz | head -n 85 > $GATK/vcf_head.vcf 

echo "---------------------------------------"
echo "Change default language to ASCII - fewer characters than UTF8"
LC_ALL=C

echo "---------------------------------------"
echo "Filter for variants from the original vcf that are called by both callers by using grep to match patterns created above" 
bcftools view $GATK/Genotyped.vcf.gz | fgrep -f grep_patterns.txt - > $GATK/Genotyped_filtered.vcf.gz

echo "---------------------------------------"
echo "Concatenate the vcf header in the variants called by both callers"
cat $GATK/vcf_head.vcf $GATK/Genotyped_filtered.vcf.gz > $GATK/GATK_consensus.vcf

echo "---------------------------------------"
echo "Clean up GATK"
rm $GATK/Genotyped_filtered.vcf.gz
rm $GATK/vcf_head.vcf 


echo "---------------------------------------"
echo "bcftools"
echo "---------------------------------------"


echo "---------------------------------------"
echo "Use vcf_variant_names to filter the original merged vcf for variants called by both tools"

echo "---------------------------------------"
echo "Create a seperate file that contains all the header information for the vcf"
zcat $bcftools/PK_samtools_variants_only_header.raw.vcf.gz | head -n 85 > $bcftools/vcf_head.vcf 

echo "---------------------------------------"
echo "Change default language to ASCII - fewer characters than UTF8"
LC_ALL=C

echo "---------------------------------------"
echo "Filter for variants from the original vcf that are called by both callers by using grep to match patterns created above" 
bcftools view $bcftools/PK_samtools_variants_only_header.raw.vcf.gz | fgrep -f grep_patterns.txt - > $bcftools/Genotyped_filtered.vcf.gz

echo "---------------------------------------"
echo "Concatenate the vcf header in the variants called by both callers"
cat $bcftools/vcf_head.vcf $bcftools/Genotyped_filtered.vcf.gz > $bcftools/bcftools_consensus.vcf

echo "---------------------------------------"
echo "Clean up samtools"
rm $bcftools/Genotyped_filtered.vcf.gz
rm $bcftools/vcf_head.vcf 

echo "---------------------------------------"
echo "Finished "
```

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard) & 1.13 (bcftools)
File: variant_counts_from_tools.pbs

**NB**: applying the filters only creates a column with a PASS/FAIL annotation, and so the "fgrep 'PASS'" selects only those variants that pass the filter.

```{R,eval=F}
#!/bin/bash
#PBS -N Counts_from_consesnus_tools
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths and change to working directory"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests"
GATK="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/"
bcftools="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/"

mkdir $OUTDIR

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus

echo "---------------------------------------------------------------------------------------------------------------------"
echo "SNPs and Indels from tool-specific conesnsus VCF files"
echo "---------------------------------------------------------------------------------------------------------------------"


echo "---------------------------------------"
echo "GATK"


echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $GATK/GATK_consensus.vcf \
    --select-type-to-include SNP \
    -O $OUTDIR/GVCFall_SNPs_GATK.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $GATK/GATK_consensus.vcf \
    --select-type-to-include INDEL \
    -O $OUTDIR/GVCFall_INDELs_GATK.vcf


echo "---------------------------------------"
echo "samtools/bcftools"


echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $bcftools/bcftools_consensus.vcf \
    --select-type-to-include SNP \
    -O $OUTDIR/GVCFall_SNPs_bcftools.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $bcftools/bcftools_consensus.vcf \
    --select-type-to-include INDEL \
    -O $OUTDIR/GVCFall_INDELs_bcftools.vcf



echo "---------------------------------------------------------------------------------------------------------------------"
echo "FILTERING"
echo "---------------------------------------------------------------------------------------------------------------------"



echo "------------------------------------------------------------------------------"
echo "GATK CONSENUS"
echo "------------------------------------------------------------------------------"



echo "---------------------------------------"
echo "GATK_BP"

echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_SNPs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_GATK.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_INDELs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_GATK.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_GATK_BP.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_GATK_BP.tsv



echo "---------------------------------------"
echo "VIVAX"

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_SNPs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_GATK.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_INDELs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_GATK.vcf


echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_VIVAX.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_VIVAX.tsv



echo "------------------------------------------------------------------------------"
echo "BCFTOOLS CONSENUS"
echo "------------------------------------------------------------------------------"



echo "---------------------------------------"
echo "GATK_BP"

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_SNPs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_INDELs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_GATK_BP.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_GATK_BP.tsv




echo "---------------------------------------"
echo "VIVAX"

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_SNPs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/GVCFall_INDELs_bcftools.vcf\
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_VIVAX.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_VIVAX.tsv


echo "------------------------------------------------------------------------------"
echo "Clean up"
echo "------------------------------------------------------------------------------"

cd $OUTDIR
rm snps_filtered_bcftools.vcf
rm indels_filtered_bcftools.vcf
rm snps_filtered_GATK.vcf
rm indels_filtered_GATK.vcf

echo "---------------------------------------"
echo "Finsihed"
```



### Single parameter filters 

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard)

#### GATK_BP

File: GATK_BP/variant_filtering_single_param.pbs

```{R,eval}
#!/bin/bash
#PBS -N Filter_specific_param_GATK_BP
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/specific_parameters"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir $OUTDIR
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus


echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'SNPs'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "------------------------------------------------------------------------------"
echo 'QD'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_QD.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_QD.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_QD.tsv

echo "------------------------------------------------------------------------------"
echo 'QUAL'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_QUAL.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_QUAL.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_QUAL.tsv

echo "------------------------------------------------------------------------------"
echo 'SQR'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_SQR.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_SQR.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_SQR.tsv

echo "------------------------------------------------------------------------------"
echo 'FS'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "FS > 60.0" --filter-name "FS60" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_FS.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "FS > 60.0" --filter-name "FS60" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_FS.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "FS > 60.0" --filter-name "FS60" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_FS.tsv

echo "------------------------------------------------------------------------------"
echo 'MQ'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_MQ.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_MQ.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_MQ.tsv

echo "------------------------------------------------------------------------------"
echo 'MQRankSum'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_MQRankSum.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_MQRankSum.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_MQRankSum.tsv

echo "------------------------------------------------------------------------------"
echo 'ReadPosRankSum'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_ReadPosRankSum.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_ReadPosRankSum.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_ReadPosRankSum.tsv



echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'INDELS'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "------------------------------------------------------------------------------"
echo 'QD'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_QD.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_QD.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_QD.tsv

echo "------------------------------------------------------------------------------"
echo 'QUAL'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_QUAL.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_QUAL.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_QUAL.tsv

echo "------------------------------------------------------------------------------"
echo 'FS'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "FS > 200.0" --filter-name "FS200" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_FS.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "FS > 200.0" --filter-name "FS200" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_FS.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "FS > 200.0" --filter-name "FS200" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_FS.tsv

echo "------------------------------------------------------------------------------"
echo 'ReadPosRankSum'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_ReadPosRankSum.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_ReadPosRankSum.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_ReadPosRankSum.tsv


echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'CLEAN UP'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
rm $OUTDIR/*filtered*


echo "---------------------------------------"
echo 'Finished'
```

#### Vivax

File: Vivax/variant_filtering_single_param.pbs

```{R,eval}
#!/bin/bash
#PBS -N Filter_specific_param_Vivax
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=21
#PBS -l mem=100gb
#PBS -l walltime=48:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/specific_parameters"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
mkdir $OUTDIR
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus


echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'SNPs'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "------------------------------------------------------------------------------"
echo 'QD'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_QD.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_QD.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_QD.tsv

echo "------------------------------------------------------------------------------"
echo 'FS'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_FS.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_FS.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_FS.tsv

echo "------------------------------------------------------------------------------"
echo 'MQ'
echo "------------------------------------------------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_SNPs.vcf \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/SNPs_consensus_MQ.tsv

echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_SNPs_GATK.vcf \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_MQ.tsv

echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_SNPs_bcftools.vcf \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_MQ.tsv

echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'INDELS'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "------------------------------------------------------------------------------"
echo 'QD'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_QD.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_QD.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_QD.tsv


echo "------------------------------------------------------------------------------"
echo 'FS'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_FS.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_FS.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_FS.tsv

echo 'MQ'
echo "------------------------------------------------------------------------------"
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V variants_only_test/GVCFall_INDELs.vcf \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/indels_consensus_MQ.tsv


echo "---------------------------------------"
echo "Filter applied to pre-merged tool-specific data"


echo "---------------------------------------"
echo 'GATK'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GATK/GVCFall_INDELs_GATK.vcf \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_GATK.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_MQ.tsv


echo "---------------------------------------"
echo 'samtools'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V samtools/GVCFall_INDELs_bcftools.vcf \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_MQ.tsv


echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'CLEAN UP'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
rm $OUTDIR/*filtered*


echo "---------------------------------------"
echo 'Finished'
```

#### Get Variant Counts

To get the counts for the different single parameter tests that can be wrangled into a summary in R Studio, we use:

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/GATK_BP/specific_parameters
wc -l * > variant_counts_for_specific_param_GATK_BP.tsv

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/specific_parameters
wc -l * > variant_counts_for_specific_param_Vivax.tsv


#### Get variant counts from consensus-only tool-sepcific VCF files

The previous counts obtained for the pre-consensus vairant counts from bcftools and GATK may not provide much meaning, as we may only be interested in how the filters would effect the remaining variants in the PK consenus VCF.
However, to obtain these we have to 'filter' the VCF outputs from the specific tools for the conesnus variants usng fgrep, and then apply the same filters we used above to these tool-specific consensus variants.

Files to accomplish this are located in the directory pk_pipeline/ZB_100/scripts/14_Consensus_vcf/filtering_test/tool_spec_consensus. 
Files:
consensus_variats_from_tools.pbs
variant_counts_from_consensus_tools.pbs
filtering_single_param_GATK_BP.pbs
filtering_single_param_vivax.pbs


### Compare the number/percentage of variants filtered out in those variants that are unique to each tool

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard) & 1.13 (bcftools).

File: unique_variants_from_tools.pbs

```{R,eval=f}
#!/bin/bash
#PBS -N Unique_variants_from_tools
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=30
#PBS -l mem=300gb
#PBS -l pmem=300gb
#PBS -l file=200gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths and set variables"
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/bcftools-1.13/
GATK="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/"
bcftools="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/variants_only_test/


echo "---------------------------------------------------------------------------------------------------------------------"
echo "GATK"
echo "---------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo "Change default language to ASCII - fewer characters than UTF8"
LC_ALL=C

echo "---------------------------------------"
echo "Filter for variants from the original vcf that are called by both callers by using grep to match patterns created above" 
bcftools view $GATK/Genotyped.vcf.gz | fgrep -v -f grep_patterns.txt - > $GATK/GATK_unique.vcf


echo "---------------------------------------------------------------------------------------------------------------------"
echo "bcftools"
echo "---------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo "Filter for variants from the original vcf that are called by both callers by using grep to match patterns created above" 
bcftools view $bcftools/PK_samtools_variants_only_header.raw.vcf.gz | fgrep -v -f grep_patterns.txt - > $bcftools/bcftools_unique.vcf

echo "---------------------------------------"
echo "Finished "
```


File: unique_filterin.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Filtering_unique_variants
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths and change to working directory"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
GATK="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/"
samtools="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/samtools/"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/unique/"

mkdir $OUTDIR

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus


echo "---------------------------------------"
echo "GATK"


echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $GATK/GATK_unique.vcf \
    --select-type-to-include SNP \
    -O $OUTDIR/unique_SNPs_GATK.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $GATK/GATK_unique.vcf \
    --select-type-to-include INDEL \
    -O $OUTDIR/unique_INDELs_GATK.vcf


echo "---------------------------------------"
echo "samtools/bcftools"


echo "---------------------------------------"
echo "SNPs"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $samtools/bcftools_unique.vcf \
    --select-type-to-include SNP \
    -O $OUTDIR/unique_SNPs_bcftools.vcf

echo "---------------------------------------"
echo "Indels"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    SelectVariants \
    -R $INDEXTDIR \
    -V $samtools/bcftools_unique.vcf \
    --select-type-to-include INDEL \
    -O $OUTDIR/unique_INDELs_bcftools.vcf



echo "---------------------------------------------------------------------------------------------------------------------"
echo "FILTERING"
echo "---------------------------------------------------------------------------------------------------------------------"

echo "------------------------------------------------------------------------------"
echo "ORIGINAL"
echo "------------------------------------------------------------------------------"

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/unique_SNPs_GATK.vcf > $OUTDIR/SNPs_GATK_original.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/unique_INDELs_GATK.vcf > $OUTDIR/indels_GATK_original.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/unique_SNPs_bcftools.vcf > $OUTDIR/SNPs_bcftools_original.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/unique_INDELs_bcftools.vcf > $OUTDIR/indels_bcftools_original.tsv


echo "------------------------------------------------------------------------------"
echo "GATK CONSENUS"
echo "------------------------------------------------------------------------------"


echo "---------------------------------------"
echo "GATK_BP"

echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_SNPs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_GATK.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_INDELs_GATK.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_GATK.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_GATK_BP.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_GATK_BP.tsv


echo "---------------------------------------"
echo "VIVAX"

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_SNPs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_GATK.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_INDELs_GATK.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_GATK.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/SNPs_GATK_VIVAX.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_GATK.vcf | fgrep 'PASS' > $OUTDIR/indels_GATK_VIVAX.tsv


echo "------------------------------------------------------------------------------"
echo "BCFTOOLS CONSENUS"
echo "------------------------------------------------------------------------------"


echo "---------------------------------------"
echo "GATK_BP"

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_SNPs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "SOR > 3.0" --filter-name "SOR3" \
    -filter "FS > 60.0" --filter-name "FS60" \
    -filter "MQ < 40.0" --filter-name "MQ40" \
    -filter "MQRankSum < -12.5" --filter-name "MQRankSum-12.5" \
    -filter "ReadPosRankSum < -8.0" --filter-name "ReadPosRankSum-8" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_INDELs_bcftools.vcf \
    -filter "QD < 2.0" --filter-name "QD2" \
    -filter "QUAL < 30.0" --filter-name "QUAL30" \
    -filter "FS > 200.0" --filter-name "FS200" \
    -filter "ReadPosRankSum < -20.0" --filter-name "ReadPosRankSum-20" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_GATK_BP.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_GATK_BP.tsv




echo "---------------------------------------"
echo "VIVAX"

echo "---------------------------------------"
echo 'filter snps'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_SNPs_bcftools.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/snps_filtered_bcftools.vcf

echo "---------------------------------------"
echo 'filter indels'
/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V $OUTDIR/unique_INDELs_bcftools.vcf\
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/indels_filtered_bcftools.vcf

echo "---------------------------------------"
echo "Exectute bcftools to select variants"
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/snps_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/SNPs_bcftools_VIVAX.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/indels_filtered_bcftools.vcf | fgrep 'PASS' > $OUTDIR/indels_bcftools_VIVAX.tsv


echo "------------------------------------------------------------------------------"
echo "Clean up"
echo "------------------------------------------------------------------------------"

cd $OUTDIR
rm *vcf*

echo "---------------------------------------"
echo "Finished"
```

To get the counts for the different single parameter tests that can be wrangled into a summary in R Studio, we use:

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/unique/
wc -l * > unique_variants.tsv


### Adjusting the values in the Vivax filter

Although it appears that the vivax filters were the most appropriate of the two conbinations tested, the values were are based on a Vivax dataset.
So next we looked at the distribution of scores for the annotations used in the Vivax filter to come up with some values that are specific to Pk.
We tried several values and combinations. The script below represents the combination we thought was best.

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard) & 1.13 (bcftools).

File: variant_filtering_adjusted.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Filter_variants
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/adjusted"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus

echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'QD'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo 'FILTER'
echo "---------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/QD_snps_filtered.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/QD_indels_filtered.vcf

echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/QD_snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/QD_SNPs.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/QD_indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/QD_indels.tsv


echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'FS'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo 'FILTER'
echo "---------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/FS_snps_filtered.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/FS_indels_filtered.vcf

echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/FS_snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/FS_SNPs.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/FS_indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/FS_indels.tsv

echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'MQ'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo 'FILTER'
echo "---------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/MQ_snps_filtered.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/MQ_indels_filtered.vcf

echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/MQ_snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/MQ_SNPs.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/MQ_indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/MQ_indels.tsv

echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'ALL'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo 'FILTER'
echo "---------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/ALL_snps_filtered.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/ALL_indels_filtered.vcf

echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/ALL_snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/ALL_SNPs.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/ALL_indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/ALL_indels.tsv

echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"
echo 'ORIGINAL'
echo "------------------------------------------------------------------------------------------------------------------------------------------------------------"

echo "---------------------------------------"
echo 'FILTER'
echo "---------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/Vivax_snps_filtered.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 12.43" --filter-name "QD2" \
    -filter "FS > 14.63418" --filter-name "FS60" \
    -filter "MQ < 51.6" --filter-name "MQ40" \
    -O $OUTDIR/Vivax_indels_filtered.vcf

echo "---------------------------------------"
echo 'Query data for download/comparison'
echo "---------------------------------------"

bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/Vivax_snps_filtered.vcf | fgrep 'PASS' > $OUTDIR/Vivax_SNPs.tsv
bcftools query -f '%CHROM %POS %ID %REF %ALT %FILTER [\t%SAMPLE DP=%DP GQ=%GQ MQ=%MQ PL=%PL]\n' $OUTDIR/Vivax_indels_filtered.vcf | fgrep 'PASS' > $OUTDIR/Vivax_indels.tsv

echo "---------------------------------------------------------------------------------------------------------------------"
echo 'Tidy up'
echo "---------------------------------------------------------------------------------------------------------------------"
cd $OUTDIR
wc -l *tsv > adjusted_filters_4.tsv
rm *filtered*

echo "---------------------------------------"
echo 'Finished'

```

# Creating final variant truth set VCF

**To be used for bam preprocessing etc.**

Here we create a VCF that only contains those variants that make it passed the desired filtering parameters.

Versions: 4.2.2 (GATK), 1.8.0_131-b1 (Java), 2.21.9 (picard) & 1.13 (bcftools).

File: truth_set_VCF.pbs

```{R,eval=F}
#!/bin/bash
#PBS -N Truth_Set
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=24:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/bcftools-1.13/
OUTDIR="/home/jwestaway/pk_pipeline/ref_genomes/variants"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus

echo "---------------------------------------"
echo 'FILTER'
echo "---------------------------------------"

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V PK_consensus.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/PK_consensus_FILTERED.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_SNPs.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/FILTERED_SNPs.vcf

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /home/jwestaway/pk_pipeline/tools/gatk-4.2.2.0/gatk-package-4.2.2.0-local.jar \
    VariantFiltration \
    -V GVCFall_INDELs.vcf \
    -filter "QD < 20.0" --filter-name "QD2" \
    -filter "FS > 2.0" --filter-name "FS60" \
    -filter "MQ < 59.0" --filter-name "MQ40" \
    -O $OUTDIR/FILTERED_INDELs.vcf

echo "---------------------------------------"
echo 'Wrangle VCF files to get PASS variants'
echo "---------------------------------------"
cd $OUTDIR

bcftools view FILTERED_SNPs.vcf | sed '/#CHROM/q' > FILTERED_SNPs_head.vcf 
bcftools view FILTERED_INDELs.vcf |  sed '/#CHROM/q' > FILTERED_INDELs_head.vcf 
bcftools view PK_consensus_FILTERED.vcf |  sed '/#CHROM/q' > FILTERED_consensus_head.vcf 

bcftools view FILTERED_SNPs.vcf | fgrep 'PASS' - > FILTERED_SNPs_variants.vcf 
bcftools view FILTERED_INDELs.vcf | fgrep 'PASS' - > FILTERED_INDELs_variants.vcf 
bcftools view PK_consensus_FILTERED.vcf | fgrep 'PASS' - > FILTERED_consensus_variants.vcf

cat FILTERED_SNPs_head.vcf FILTERED_SNPs_variants.vcf > TRUE_SNPs.vcf
cat FILTERED_INDELs_head.vcf FILTERED_INDELs_variants.vcf > TRUE_INDELs.vcf
cat FILTERED_consensus_head.vcf FILTERED_consensus_variants.vcf > TRUE_consensus.vcf

echo "---------------------------------------"
echo 'CLEAN UP'
echo "---------------------------------------"
rm *head*
rm *variants*

echo "---------------------------------------"
echo 'Finished'

```

## Steps to create final truth set

	• Bam pre-processing
		○ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/bam_preprocessing.pbs
	• Variant calling
		○ GATK
			§ Haplotype caller
				□ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/GATK/high_parasitemia/Template.pbs
				□ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/GATK/low_parasitemia/Template.pbs
				□ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/GATK/previous_Pk_data/Template.pbs
			§ Interactive - GVCFs to the same location
				□ `mkdir /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs`
				□ `mv /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/*/*.haplotypecaller.g.vcf.gz /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs`
				□ `mv /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/*/*.haplotypecaller.g.vcf.gz.tbi /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/GVCFs`
			§ Combine GVCFs and Genotype caller
				□ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/GATK/joint_genotype.pbs
		○ Bcftools 
			§ Interactive 
				□ 'mkdir cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams'
				□ 'mv /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/*/*.dupmarked.reheader.bam /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams'
				□ '''ls /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/GATK/bams/*.dupmarked.reheader.bam \
				   | tr '\n' '\0' | xargs -0 -n 1 basename \
				   > input_bam_files.list'''
			§ Mpileup and call
				□ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/variants_only_test/bcftools_variants_only.pbs
	• Merge variants 
		○ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/variants_only_test/samtools_merge_vcfs.pbs
	• Create consensus VCF
		○ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/variants_only_test/Consensus_variants.pbs
			§ Nested in above script - /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/vcf_wrangle_2.R 
	• Filter consensus VCF
		○ Create VCFs for SNPs and Indels from consensus VCF
			§ /home/jwestaway/pk_pipeline/ZB_100/scripts/14_Consensus_vcf/filtering_test/snps_and_indels.pbs
	• Create final truth set
		○ Filter with vivax annotations and adjusted parameters, and then use fgrep to select only those variants that pass the filter - this is our conservative set of variants that can be used for bam pre processing etc.
/home/jwestaway/pk_pipeline/ref_genomes/variants/truth_set_VCF.pbs


# Variant annotation

Here we annotate the truth set of variants using ensembl.
We first needed to modify our GFF file:
  • Change the contig names to match the reference genome and VCF files.
  • Substitute protein_coding_gene for gene.
  • Sort and modfiy the structure to suit ensembl requirements.

Versions: 5.26 (perl) & 104 (ensembl).

File: /home/jwestaway/pk_pipeline/ZB_100/scripts/15_variant_annotation/ensembl/annotate_variants.pbs


```{R,eval=F}
#!/bin/bash
#PBS -N Annotate_variants
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=16
#PBS -l mem=50gb
#PBS -l walltime=12:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'
module load perl/5.26.0
export PATH=$PATH:/home/jwestaway/pk_pipeline/tools/ensembl-vep-release-104
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/variant_annotation"
GFF="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/gff/updated_version"
FASTA="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"

mkdir $OUTDIR

echo "---------------------------------------------------------------------------------------------------------------------"
echo "Sort, Zip and Index GFF"
cd $GFF

grep -v "#" PlasmoDB-55_PknowlesiA1H1.gff |\
    sed -e 's/LT727648/ordered_PKNH_01_v2/g' |\
    sed -e 's/LT727649/ordered_PKNH_02_v2/g' |\
    sed -e 's/LT727650/ordered_PKNH_03_v2/g' |\
    sed -e 's/LT727651/ordered_PKNH_04_v2/g' |\
    sed -e 's/LT727652/ordered_PKNH_05_v2/g' |\
    sed -e 's/LT727653/ordered_PKNH_06_v2/g' |\
    sed -e 's/LT727654/ordered_PKNH_07_v2/g' |\
    sed -e 's/LT727655/ordered_PKNH_08_v2/g' |\
    sed -e 's/LT727656/ordered_PKNH_09_v2/g' |\
    sed -e 's/LT727657/ordered_PKNH_10_v2/g' |\
    sed -e 's/LT727658/ordered_PKNH_11_v2/g' |\
    sed -e 's/LT727659/ordered_PKNH_12_v2/g' |\
    sed -e 's/LT727660/ordered_PKNH_13_v2/g' |\
    sed -e 's/LT727661/ordered_PKNH_14_v2/g' |\
    sed -e 's/LT727662/PKNH_MIT_v2/g' |\
    sed -e 's/LT727663/new_API_strain_A1_H.1/g' |\
    sed -e 's/protein_coding_gene/gene/g' | sort -k1,1 -k4,4n -k5,5n -t$'\t' | bgzip -c > PlasmoDB-55_PknowlesiA1H1.gff.gz

tabix -p gff PlasmoDB-55_PknowlesiA1H1.gff.gz

echo "---------------------------------------------------------------------------------------------------------------------"
echo "Change to working directoy"
cd /home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/filtering_tests/Vivax/

echo "---------------------------------------------------------------------------------------------------------------------"
echo "SNPs"
vep -i snps_filtered.vcf --gff $GFF/PlasmoDB-55_PknowlesiA1H1.gff.gz --fasta $FASTA -o $OUTDIR/SNP_variant_annotation.txt 

echo "---------------------------------------------------------------------------------------------------------------------"
echo "INDELs"
vep -i indels_filtered.vcf --gff $GFF/PlasmoDB-55_PknowlesiA1H1.gff.gz --fasta $FASTA -o $OUTDIR/Indel_variant_annotation.txt 

echo "---------------------------------------"
echo "FINISHED"


```



































# Bam Preprocessing 


Jobs split and run as a PBS script for each sample.

> cd /home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment
> ls *.bam | sed 's/.bam//' > sample_names.txt

> for i in $(cat sample_names.txt)
> do
> sed s/SAMPLE/$i/g Indel_realignment_template.pbs > ${i}.pbs
> done

> for file in *L4.pbs; do qsub $file; done

The resulting files can be found in **????????????????**, and an example is given below.
File = PK_SB_DNA_006_DKDL210002135-1a_HWHGKDSXY_L4.pbs
Version(s) = 1.12 (samtools), 1.8.0_131-b1 (Java), 2.21.9 (picard), 3.2.2 (GATK), 4.2.2 (GATK - updated for haplotype caller).

GATK is run through Java, which requires compatible [jdk and jre](https://www.guru99.com/difference-between-jdk-jre-jvm.html#:~:text=The%20full%20form%20of%20JDK%20is%20Java%20Development,also%20platform%20dependent%2C%20but%20JVM%20is%20platform%20independent. installations).
Java uses a [Picard](https://github.com/broadinstitute/picard) jar file to run GATK.


GATK does not provide support for previous iterations of their software, so any additional information required needs to be obtained using `--help`.
Arguments:
  - T - GATK tool
  - intervals - genomic intervals (i.e. contigs and their base positon - BED file)
  - known - known **indels** - VCF file
  - knownsites - known **variants** - VCF file
  - consensusDeterminationModel - model for computing possible alternates - KNOWNS_ONLY uses known indels only
  - LOD - threshold for cleaning above
  - ERC - mode for emitting experimental reference confidence scores 
  - minPruning - minimum allowed pruning factor in assembly graph - paths with < x supporting kmers are pruned for the graph
  - maxNumHaplotypesInPopulation - self explanatory - number needs to be increased when calling organisms with high heterozygosity
  - variant_index_type - type of index creator
  - variant_index_parameter - to be passed to the VCF index creator
  - contamination - fraction of contamination in seq data to aggresively remove 
  - G - annotation
  - hets - heterozygosity value to be used to compute likelihoods 
  - indelHeterozygosity - heterozygosity value to be used for variant calling

Calculate approximate heterozygosity (needed for -hets and -indelHeterozygosity arguments):

Approximate heterozygosity = ((number of sites with Indels)/(Total number of sites))*(1-(average number of homozygous genotypes per site)/(total number of individuals))

To calculate the average number of homozygous genotypes per site:

`bcftools view -v snps PK_consensus_corrected.vcf > PK_consensus_corrected_snps.vcf`
`bcftools view -v snps PK_consensus_corrected.vcf > PK_consensus_corrected_indels.vcf`

`awk -F\0\/0: '!/^ *#/ {total += NF-1; count++} END { print total/count }' PK_consensus_corrected_indels.vcf` = 33.4156
`awk -F\0\/0: '!/^ *#/ {total += NF-1; count++} END { print total/count }' PK_consensus_corrected_snps.vcf` = 46.0537

To calculate the number of sites with indels:
(Lines in VCF) - (Lines in VCF header)
bcftools view PK_consensus_corrected_indels.vcf | wc -l 
135618 - 81 = 135537 = number of sites with indels 

To calculate the number of sites with SNPs:
(Lines in VCF) - (Lines in VCF header)
bcftools view PK_consensus_corrected_snps.vcf | wc -l 
1536942 - 81 = 1536861 

Total number of sites/bases:

24301727


Indels: (135537 / 24301727) * (1 - (33.42 / 78)) = 0.0032 
SNPs: (1536861 / 24301727) * (1 - (46.05 / 78)) = 0.0259 
Indels and SNPs : ((135537 + 1536861) / 24301727) * (1 - ((33.42 + 46.05) / 78)) = -0.0013 

## MAYBE
GATK threw an error in relation to a number being a string, "R", and so this needed to be amended.
mv TRUE_INDELs.vcf TRUE_INDELs_original.vcf
cat TRUE_INDELs_original.vcf | sed 's/AD,Number=R/AD,Number=1/' > TRUE_INDELs.vcf
mv TRUE_SNPs.vcf TRUE_SNPs_original.vcf
cat TRUE_SNPs_original.vcf | sed 's/AD,Number=R/AD,Number=1/' > TRUE_SNPs.vcf
mv TRUE_consensus.vcf TRUE_consensus_original.vcf
cat TRUE_consensus_original.vcf | sed 's/AD,Number=R/AD,Number=1/' > TRUE_consensus.vcf

```{R,eval=F}
#!/bin/bash
#PBS -N Indel_Realign_ZB_Test
#PBS -j oe
#PBS -m ae
#PBS -l nodes=1
#PBS -l ncpus=11
#PBS -l mem=50gb
#PBS -l walltime=12:00:00
#PBS -M jacob.westaway@menzies.edu.au

echo "---------------------------------------"
echo "PBS: Job identifier is $PBS_JOBID"
echo "PBS: Job name is $PBS_JOBNAME"

echo "---------------------------------------"
echo "Define paths to samtools"
export PATH=$PATH:/usr/local/jdk1.8.0_131/bin
export PATH=$PATH:/usr/local/jre1.8.0_111/bin
export PATH=$PATH:/usr/local/GenomeAnalysisTK-3.2.2 
export PATH=$PATH:/usr/local/miniconda3/envs/assembly/bin/

echo "---------------------------------------"
echo "---------------------------------------"
echo 'Change to working directory and set env variables'

INDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment/"
OUTDIR="/home/jwestaway/pk_pipeline/ZB_100/outputs/variant_calling/SAMPLE"
PICARD="/usr/local/miniconda3/pkgs/picard-2.21.9-0/share/picard-2.21.9-0/picard.jar"
INDEXTDIR="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/fasta/strain_A1_H.1.Icor.fasta"
INTERVALS="/home/jwestaway/pk_pipeline/ref_genomes/PKA1H1/strain_A1_H.1.Icor.fasta.bed"
KNOWNSITES="/home/jwestaway/pk_pipeline/ZB_100/outputs/vcf_consensus/"

mkdir $OUTDIR
 
echo "---------------------------------------"
echo 'Sort and Index bam files'

cd /home/jwestaway/pk_pipeline/ZB_100/outputs/direct_alignment

samtools sort -@ 10 SAMPLE.bam > SAMPLE.sorted.bam

samtools index -@ 10 SAMPLE.sorted.bam

echo "---------------------------------------"
echo 'MarkDuplicates'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -jar $PICARD \
    MarkDuplicates AS=TRUE VALIDATION_STRINGENCY=LENIENT \
    I=$INDIR/SAMPLE.sorted.bam \
    O=$OUTDIR/SAMPLE.dupmarked.bam \
    M=$OUTDIR/SAMPLE_picard_metrics_file.txt 

echo "---------------------------------------"
echo 'Change header @RG and index' 

samtools view -H $OUTDIR/SAMPLE.dupmarked.bam | \
    sed 's,^@RG.*,@RG\tID:SAMPLE\tSM:SAMPLE\tLB:None\tPL:Illumina,g' |  \
    samtools reheader - $OUTDIR/SAMPLE.dupmarked.bam > $OUTDIR/SAMPLE.dupmarked.reheader.bam

samtools index $OUTDIR/SAMPLE.dupmarked.reheader.bam 

echo "---------------------------------------"
echo 'RealignerTargetCreator'

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T RealignerTargetCreator \
    -nt 10 \
    -R $INDEXTDIR \
    -I $OUTDIR/SAMPLE.dupmarked.reheader.bam \
    --intervals $INTERVALS \
    -known $KNOWNSITES/PK_consensus_corrected_indels.vcf \
    -o $OUTDIR/SAMPLE.dupmarked.realigner.intervals

echo "---------------------------------------"
echo 'IndelRealigner' 

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T IndelRealigner \
    --consensusDeterminationModel KNOWNS_ONLY \
    -LOD 0.4 \
    -R $INDEXTDIR \
    -I $OUTDIR/SAMPLE.dupmarked.reheader.bam \
    --intervals $INTERVALS \
    -known $KNOWNSITES/PK_consensus_corrected_indels.vcf \
    -targetIntervals $OUTDIR/SAMPLE.dupmarked.realigner.intervals \
    -o $OUTDIR/SAMPLE.dupmarked.realigned.bam

echo "---------------------------------------"
echo 'BaseRecalibrator - create recal table' 

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T BaseRecalibrator \
    -R $INDEXTDIR \
    -I $OUTDIR/SAMPLE.dupmarked.realigned.bam \
    --intervals $INTERVALS \
    -knownSites $KNOWNSITES/PK_consensus_corrected.vcf \
    -o $OUTDIR/SAMPLE.dupmarked.realigned.recal.table

echo "---------------------------------------"
echo 'PrintReads - get recal reads' 

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar  \
    -T PrintReads \
    -R $INDEXTDIR \
    --intervals $INTERVALS \
    -I $OUTDIR/SAMPLE.dupmarked.realigned.bam \
    -BQSR $OUTDIR/SAMPLE.dupmarked.realigned.recal.table \
    -o $OUTDIR/SAMPLE.dupmarked.realigned.recal.bam

echo "---------------------------------------"
echo 'HaplotypeCaller' 

/usr/local/jdk1.8.0_131/bin/java -Djava.iodir=$PBS_JOBFS -Xms3200m -Xmx3600m -jar /usr/local/GenomeAnalysisTK-3.2.2/GenomeAnalysisTK.jar \
    -T HaplotypeCaller \
    -ERC GVCF \
    --minPruning 3 \
    --maxNumHaplotypesInPopulation 200 \
    --variant_index_type LINEAR \
    --variant_index_parameter 128000 \
    -contamination 0.0 \
    -G Standard \
    -R $INDEXTDIR \
    --intervals $INTERVALS \
    -hets 0.015 \
    -indelHeterozygosity 0.01 \
    -I $OUTDIR/SAMPLE.dupmarked.realigned.recal.bam \
    -o $OUTDIR/SAMPLE.dupmarked.realigned.recal.vcf.gz

echo "---------------------------------------"
echo 'Finished' 
```